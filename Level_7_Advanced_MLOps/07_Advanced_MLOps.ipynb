{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 7: Advanced MLOps - Uygulamalar\n",
    "\n",
    "Bu notebook, ileri seviye MLOps konularını pratik örneklerle açıklamaktadır.\n",
    "\n",
    "**Not:** Başlamadan önce bu seviyenin gereksinimlerini kurduğunuzdan emin olun:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-Model Orchestration (Çoklu Model Orkestrasyonu)\n",
    "\n",
    "Bu örnekte, `Ray Serve` kullanarak gelen isteklere göre farklı modellere yönlendirme yapan basit bir yapı kuracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "from starlette.requests import Request\n",
    "\n",
    "# Ray'i başlat (eğer zaten çalışmıyorsa)\n",
    "if not ray.is_initialized():\n",
    "    ray.init(num_cpus=4)\n",
    "\n",
    "# Serve'i başlat\n",
    "serve.start()\n",
    "\n",
    "@serve.deployment(name=\"model_a\")\n",
    "class ModelA:\n",
    "    def predict(self, data):\n",
    "        return {\"model\": \"A\", \"prediction\": data * 2}\n",
    "\n",
    "@serve.deployment(name=\"model_b\")\n",
    "class ModelB:\n",
    "    def predict(self, data):\n",
    "        return {\"model\": \"B\", \"prediction\": data + 5}\n",
    "\n",
    "@serve.deployment(route_prefix=\"/invocations\")\n",
    "class Router:\n",
    "    def __init__(self, model_a_handle, model_b_handle):\n",
    "        self.model_a = model_a_handle\n",
    "        self.model_b = model_b_handle\n",
    "\n",
    "    async def __call__(self, request: Request):\n",
    "        data = await request.json()\n",
    "        input_data = data['input']\n",
    "\n",
    "        # Basit yönlendirme mantığı: Girdi 10'dan büyükse Model B'yi kullan\n",
    "        if input_data > 10:\n",
    "            result = await self.model_b.predict.remote(input_data)\n",
    "        else:\n",
    "            result = await self.model_a.predict.remote(input_data)\n",
    "        \n",
    "        return result\n",
    "\n",
    "ModelA.deploy()\n",
    "ModelB.deploy()\n",
    "Router.deploy(ModelA.get_handle(), ModelB.get_handle())\n",
    "\n",
    "print(\"Modeller ve yönlendirici dağıtıldı.\")\n",
    "print(\"Test etmek için yeni bir terminalde şu komutları kullanabilirsiniz:\")\n",
    "print(\"curl -X POST -H 'Content-Type: application/json' -d '{\\\"input\\\": 5}' http://localhost:8000/invocations\")\n",
    "print(\"curl -X POST -H 'Content-Type: application/json' -d '{\\\"input\\\": 15}' http://localhost:8000/invocations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A/B Testing\n",
    "\n",
    "İki modelin (A ve B) dönüşüm oranlarını karşılaştırmak için basit bir istatistiksel test (Z-testi) yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Model A'nın sonuçları\n",
    "visitors_A = 1000\n",
    "conversions_A = 100  # %10 dönüşüm oranı\n",
    "\n",
    "# Model B'nin sonuçları\n",
    "visitors_B = 1050\n",
    "conversions_B = 125  # ~%11.9 dönüşüm oranı\n",
    "\n",
    "# Z-testi uygulama\n",
    "count = np.array([conversions_A, conversions_B])\n",
    "nobs = np.array([visitors_A, visitors_B])\n",
    "\n",
    "stat, p_value = proportions_ztest(count, nobs)\n",
    "\n",
    "print(f\"Z-istatistiği: {stat:.4f}\")\n",
    "print(f\"P-değeri: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05  # Anlamlılık seviyesi\n",
    "if p_value < alpha:\n",
    "    print(\"Sonuç istatistiksel olarak anlamlı: Model B, Model A'dan daha iyi performans gösteriyor.\")\n",
    "else:\n",
    "    print(\"Sonuç istatistiksel olarak anlamlı değil: İki model arasında anlamlı bir fark yoktur.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Store Management (Özellik Deposu Yönetimi)\n",
    "\n",
    "`Feast` kullanarak basit bir yerel özellik deposu oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# 1. Adım: Örnek verileri ve Feast deposu yapısını oluştur\n",
    "if not os.path.exists('feature_repo/data'):\n",
    "    os.makedirs('feature_repo/data')\n",
    "\n",
    "user_data = pd.DataFrame({\n",
    "    \"event_timestamp\": [pd.to_datetime(datetime.now() - timedelta(days=i)) for i in range(5)],\n",
    "    \"user_id\": [101, 102, 101, 103, 102],\n",
    "    \"daily_transactions\": [5, 8, 3, 1, 9],\n",
    "    \"avg_spend\": [50.0, 120.5, 45.0, 20.0, 150.8]\n",
    "})\n",
    "user_data_path = \"feature_repo/data/user_data.parquet\"\n",
    "user_data.to_parquet(user_data_path)\n",
    "\n",
    "print(f\"Örnek veri '{user_data_path}' dosyasına kaydedildi.\")\n",
    "\n",
    "# `feast init` komutu normalde bir CLI'dan çalıştırılır.\n",
    "# Burada manuel olarak gerekli dosyaları oluşturacağız.\n",
    "feature_repo_py = \"\"\"\n",
    "from feast import Entity, Feature, FeatureView, FileSource, ValueType\n",
    "from datetime import timedelta\n",
    "\n",
    "user_data = FileSource(\n",
    "    path=\"data/user_data.parquet\",\n",
    "    event_timestamp_column=\"event_timestamp\",\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user_id\", value_type=ValueType.INT64, description=\"User ID\")\n",
    "\n",
    "user_features_view = FeatureView(\n",
    "    name=\"user_features\",\n",
    "    entities=[\"user_id\"],\n",
    "    ttl=timedelta(days=1),\n",
    "    features=[\n",
    "        Feature(name=\"daily_transactions\", dtype=ValueType.INT64),\n",
    "        Feature(name=\"avg_spend\", dtype=ValueType.FLOAT),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=user_data,\n",
    "    tags={},\n",
    ")\n",
    "\"\"\"\n",
    "with open(\"feature_repo/example.py\", \"w\") as f:\n",
    "    f.write(feature_repo_py)\n",
    "\n",
    "print(\"Feast tanım dosyası 'feature_repo/example.py' oluşturuldu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Adım: Feast deposunu uygula ve özellik al\n",
    "\n",
    "# Normalde terminalde `feast apply` ve `feast materialize` çalıştırılır.\n",
    "# Notebook içinde FeatureStore nesnesini kullanarak bu işlemleri simüle edebiliriz.\n",
    "\n",
    "from feast import FeatureStore\n",
    "\n",
    "try:\n",
    "    # Depoyu kur\n",
    "    store = FeatureStore(repo_path=\"./feature_repo\")\n",
    "\n",
    "    print(\"\\n--- Online Store'dan Özellik Alma ---\")\n",
    "    # Özellikleri almak için bir varlık DataFrame'i oluştur\n",
    "    entity_df = pd.DataFrame.from_dict({\n",
    "        \"user_id\": [101, 102, 104], # 104 id'li kullanıcı veride yok\n",
    "        \"event_timestamp\": [datetime.now()] * 3\n",
    "    })\n",
    "\n",
    "    # Online store'dan en güncel özellikleri al\n",
    "    # Bunun için önce `feast materialize` komutuyla verinin online store'a yüklenmesi gerekir.\n",
    "    # Bu notebook'ta sadece offline alımı gösteriyoruz.\n",
    "\n",
    "    print(\"\\n--- Offline Store'dan Geçmiş Özellikleri Alma ---\")\n",
    "    # Model eğitimi için geçmiş özellikleri al\n",
    "    training_df = store.get_historical_features(\n",
    "        entity_df=entity_df,\n",
    "        feature_refs=[\n",
    "            'user_features:daily_transactions',\n",
    "            'user_features:avg_spend'\n",
    "        ],\n",
    "    ).to_df()\n",
    "\n",
    "    print(\"Eğitim için alınan özellikler:\")\n",
    "    print(training_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Bir hata oluştu: {e}\")\n",
    "    print(\"Lütfen 'feature_repo' dizininde `feast apply` ve `feast materialize-incremental 2024-01-01T00:00:00` komutlarını çalıştırarak deneyin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLOps Best Practices (MLOps İyi Uygulamaları)\n",
    "\n",
    "Bu bölüm, koddan ziyade kavramsal bir özettir. `Advanced_MLOps_Kavramlar.md` dosyasında detayları bulabilirsiniz.\n",
    "\n",
    "- **Her Şey Kod Olarak (Everything as Code):**\n",
    "  - **Altyapı (IaC):** `Terraform`, `Pulumi`\n",
    "  - **Pipeline'lar (PaC):** `Airflow`, `Prefect`, `Kubeflow Pipelines` DAG'leri\n",
    "  - **Veri ve Modeller:** `DVC` ile versiyonlama\n",
    "\n",
    "- **CI/CD/CT:**\n",
    "  - **CI (Sürekli Entegrasyon):** Kod değişikliklerinde otomatik test ve linting (örn: GitHub Actions, Jenkins).\n",
    "  - **CD (Sürekli Dağıtım):** Testleri geçen modellerin otomatik olarak dağıtılması (örn: `Seldon`, `Kserve` ile entegrasyon).\n",
    "  - **CT (Sürekli Eğitim):** Veri veya model performansında bozulma tespit edildiğinde modelin otomatik yeniden eğitilmesi.\n",
    "\n",
    "- **İzlenebilirlik ve Gözlemlenebilirlik:**\n",
    "  - **Veri ve Model Kalitesi:** `Evidently`, `WhyLogs`, `Great Expectations`\n",
    "  - **Sistem Performansı:** `Prometheus`, `Grafana`\n",
    "\n",
    "Bu araçlar ve pratikler, MLOps yaşam döngüsünü otomatikleştirmek, güvenilir kılmak ve ölçeklendirmek için temel oluşturur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
