{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Level 4: Model Training - Model Eğitimi\n",
        "\n",
        "## 🎯 Bu Bölümde Öğrenecekleriniz:\n",
        "- Advanced model training stratejileri\n",
        "- Hyperparameter optimization (GridSearch, RandomSearch, Bayesian)\n",
        "- Cross-validation ve validation stratejileri\n",
        "- Ensemble methods ve stacking\n",
        "- Model regularization teknikleri\n",
        "- Early stopping ve learning curves\n",
        "- Distributed training\n",
        "- Model versioning ve experiment tracking\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Model Training Nedir?\n",
        "\n",
        "**Model Training**, makine öğrenmesi modellerinin performansını maksimize etmek için kapsamlı eğitim stratejilerinin uygulandığı kritik aşamadır.\n",
        "\n",
        "### 🧠 Advanced Model Training Aşamaları:\n",
        "1. **Training Strategy Design**: Eğitim stratejisi tasarlama\n",
        "2. **Hyperparameter Optimization**: Optimal parametreleri bulma\n",
        "3. **Validation Strategy**: Doğrulama stratejisi belirleme\n",
        "4. **Ensemble Methods**: Birden fazla modeli birleştirme\n",
        "5. **Regularization**: Overfitting'i önleme\n",
        "6. **Model Selection**: En iyi modeli seçme\n",
        "7. **Performance Monitoring**: Eğitim sürecini izleme\n",
        "\n",
        "### 🎯 Neden Advanced Model Training?\n",
        "- **Maximum Performance**: Model performansını maksimize etme\n",
        "- **Robust Models**: Genelleme yeteneği yüksek modeller\n",
        "- **Efficient Training**: Kaynak-verimli eğitim süreçleri\n",
        "- **Scalability**: Büyük veri setleri ile çalışabilme\n",
        "- **Production Ready**: Üretim ortamına hazır modeller\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kütüphaneleri import edelim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, \n",
        "    StratifiedKFold, KFold, TimeSeriesSplit, learning_curve, validation_curve\n",
        ")\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor,\n",
        "    VotingRegressor, StackingRegressor, BaggingRegressor\n",
        ")\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from scipy.stats import uniform, randint\n",
        "import optuna\n",
        "from itertools import combinations\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Görselleştirme ayarları\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"📦 Tüm kütüphaneler başarıyla yüklendi!\")\n",
        "print(\"🚀 Advanced Model Training eğitimine hazırız!\")\n",
        "print(f\"📅 Başlangıç zamanı: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Veri Seti Hazırlama ve MLflow Setup\n",
        "\n",
        "Advanced model training sürecini göstermek için California housing veri setini kullanacağız ve MLflow ile experiment tracking yapacağız:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MLflow experiment setup\n",
        "mlflow.set_experiment(\"Advanced_Model_Training\")\n",
        "\n",
        "# California housing veri setini yükleyelim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Veri setini yükle\n",
        "california_housing = fetch_california_housing()\n",
        "X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "y = california_housing.target\n",
        "\n",
        "print(\"🏠 California Housing Veri Seti Yüklendi!\")\n",
        "print(f\"📊 Veri boyutu: {X.shape}\")\n",
        "print(f\"🎯 Hedef değişken: Ev fiyatları (hundreds of thousands of dollars)\")\n",
        "\n",
        "# Veri setini train, validation, test olarak bölelim\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"\\n📊 Veri seti bölümü:\")\n",
        "print(f\"  • Training: {X_train.shape[0]} sample ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  • Validation: {X_val.shape[0]} sample ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  • Test: {X_test.shape[0]} sample ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "# Veri ön-işleme\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\n✅ Veri ön-işleme tamamlandı!\")\n",
        "print(f\"🎯 MLflow experiment: {mlflow.get_experiment_by_name('Advanced_Model_Training').experiment_id}\")\n",
        "\n",
        "# Temel istatistikler\n",
        "print(f\"\\n📈 Hedef değişken istatistikleri:\")\n",
        "print(f\"  Training - Ortalama: ${y_train.mean():.2f}00k, Std: ${y_train.std():.2f}00k\")\n",
        "print(f\"  Validation - Ortalama: ${y_val.mean():.2f}00k, Std: ${y_val.std():.2f}00k\")\n",
        "print(f\"  Test - Ortalama: ${y_test.mean():.2f}00k, Std: ${y_test.std():.2f}00k\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Advanced Training Strategies\n",
        "\n",
        "### 3.1 Cross-Validation Stratejileri\n",
        "\n",
        "Farklı cross-validation stratejilerini karşılaştıralım:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrossValidationAnalyzer:\n",
        "    \"\"\"Cross-validation stratejilerini analiz eden sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, X, y, random_state=42):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.random_state = random_state\n",
        "        self.results = {}\n",
        "    \n",
        "    def compare_cv_strategies(self, model, n_splits=5):\n",
        "        \"\"\"Farklı CV stratejilerini karşılaştır\"\"\"\n",
        "        \n",
        "        # Farklı CV stratejileri\n",
        "        cv_strategies = {\n",
        "            'KFold': KFold(n_splits=n_splits, shuffle=True, random_state=self.random_state),\n",
        "            'KFold (No Shuffle)': KFold(n_splits=n_splits, shuffle=False),\n",
        "        }\n",
        "        \n",
        "        print(\"🔄 Cross-validation stratejileri karşılaştırılıyor...\\n\")\n",
        "        \n",
        "        for name, cv_strategy in cv_strategies.items():\n",
        "            scores = cross_val_score(model, self.X, self.y, cv=cv_strategy, \n",
        "                                   scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "            rmse_scores = np.sqrt(-scores)\n",
        "            \n",
        "            self.results[name] = {\n",
        "                'mean_rmse': rmse_scores.mean(),\n",
        "                'std_rmse': rmse_scores.std(),\n",
        "                'scores': rmse_scores,\n",
        "                'cv_object': cv_strategy\n",
        "            }\n",
        "            \n",
        "            print(f\"📊 {name}:\")\n",
        "            print(f\"  • Mean RMSE: {rmse_scores.mean():.4f} ± {rmse_scores.std():.4f}\")\n",
        "            print(f\"  • Score range: [{rmse_scores.min():.4f}, {rmse_scores.max():.4f}]\")\n",
        "            print()\n",
        "    \n",
        "    def plot_cv_comparison(self):\n",
        "        \"\"\"CV sonuçlarını görselleştir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Önce CV analizi yapın!\")\n",
        "            return\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Box plot\n",
        "        data_for_box = [self.results[name]['scores'] for name in self.results.keys()]\n",
        "        labels = list(self.results.keys())\n",
        "        \n",
        "        ax1.boxplot(data_for_box, labels=labels)\n",
        "        ax1.set_title('📊 Cross-Validation RMSE Dağılımı')\n",
        "        ax1.set_ylabel('RMSE')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Mean ± Std plot\n",
        "        means = [self.results[name]['mean_rmse'] for name in self.results.keys()]\n",
        "        stds = [self.results[name]['std_rmse'] for name in self.results.keys()]\n",
        "        \n",
        "        x_pos = np.arange(len(labels))\n",
        "        ax2.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)\n",
        "        ax2.set_title('📈 Cross-Validation Ortalama RMSE')\n",
        "        ax2.set_ylabel('RMSE')\n",
        "        ax2.set_xticks(x_pos)\n",
        "        ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def get_best_cv_strategy(self):\n",
        "        \"\"\"En iyi CV stratejisini bul\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Önce CV analizi yapın!\")\n",
        "            return None\n",
        "        \n",
        "        best_strategy = min(self.results.keys(), \n",
        "                          key=lambda x: self.results[x]['mean_rmse'])\n",
        "        \n",
        "        print(f\"🏆 En iyi CV stratejisi: {best_strategy}\")\n",
        "        print(f\"📊 Mean RMSE: {self.results[best_strategy]['mean_rmse']:.4f}\")\n",
        "        \n",
        "        return best_strategy, self.results[best_strategy]['cv_object']\n",
        "\n",
        "# Test modeli ile CV analizi yapalım\n",
        "test_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "cv_analyzer = CrossValidationAnalyzer(X_train, y_train)\n",
        "\n",
        "# CV stratejilerini karşılaştır\n",
        "cv_analyzer.compare_cv_strategies(test_model, n_splits=5)\n",
        "\n",
        "# Sonuçları görselleştir\n",
        "cv_analyzer.plot_cv_comparison()\n",
        "\n",
        "# En iyi stratejiyi bul\n",
        "best_cv_name, best_cv = cv_analyzer.get_best_cv_strategy()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.2 Hyperparameter Optimization\n",
        "\n",
        "Hyperparameter optimization için üç farklı yaklaşımı karşılaştıracağız:\n",
        "1. **Grid Search**: Tüm kombinasyonları dener\n",
        "2. **Random Search**: Rastgele parametre kombinasyonları\n",
        "3. **Bayesian Optimization**: Akıllı parametre seçimi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyperparameterOptimizer:\n",
        "    \"\"\"Hyperparameter optimization için kapsamlı sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, X_val, y_val, cv_strategy=None, random_state=42):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.cv_strategy = cv_strategy or KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "        self.random_state = random_state\n",
        "        self.results = {}\n",
        "    \n",
        "    def grid_search_optimization(self, model, param_grid, scoring='neg_mean_squared_error'):\n",
        "        \"\"\"Grid Search ile hyperparameter optimization\"\"\"\n",
        "        print(\"🔍 Grid Search başlatılıyor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"GridSearch_Optimization\"):\n",
        "            grid_search = GridSearchCV(\n",
        "                model, param_grid, cv=self.cv_strategy, \n",
        "                scoring=scoring, n_jobs=-1, verbose=1\n",
        "            )\n",
        "            \n",
        "            grid_search.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # En iyi modeli validation seti ile test et\n",
        "            best_model = grid_search.best_estimator_\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # Sonuçları kaydet\n",
        "            results = {\n",
        "                'method': 'GridSearch',\n",
        "                'best_params': grid_search.best_params_,\n",
        "                'best_cv_score': np.sqrt(-grid_search.best_score_),\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': len(grid_search.cv_results_['params']),\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(grid_search.best_params_)\n",
        "            mlflow.log_metric(\"cv_rmse\", results['best_cv_score'])\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['GridSearch'] = results\n",
        "            \n",
        "        print(f\"✅ Grid Search tamamlandı!\")\n",
        "        print(f\"🏆 En iyi CV RMSE: {results['best_cv_score']:.4f}\")\n",
        "        print(f\"📊 Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"⏱️ Süre: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"🔢 Toplam fit sayısı: {results['total_fits']}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def random_search_optimization(self, model, param_distributions, n_iter=100, scoring='neg_mean_squared_error'):\n",
        "        \"\"\"Random Search ile hyperparameter optimization\"\"\"\n",
        "        print(\"🎲 Random Search başlatılıyor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"RandomSearch_Optimization\"):\n",
        "            random_search = RandomizedSearchCV(\n",
        "                model, param_distributions, n_iter=n_iter, cv=self.cv_strategy,\n",
        "                scoring=scoring, n_jobs=-1, random_state=self.random_state, verbose=1\n",
        "            )\n",
        "            \n",
        "            random_search.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # En iyi modeli validation seti ile test et\n",
        "            best_model = random_search.best_estimator_\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # Sonuçları kaydet\n",
        "            results = {\n",
        "                'method': 'RandomSearch',\n",
        "                'best_params': random_search.best_params_,\n",
        "                'best_cv_score': np.sqrt(-random_search.best_score_),\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': n_iter,\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(random_search.best_params_)\n",
        "            mlflow.log_metric(\"cv_rmse\", results['best_cv_score'])\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['RandomSearch'] = results\n",
        "            \n",
        "        print(f\"✅ Random Search tamamlandı!\")\n",
        "        print(f\"🏆 En iyi CV RMSE: {results['best_cv_score']:.4f}\")\n",
        "        print(f\"📊 Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"⏱️ Süre: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"🔢 Toplam fit sayısı: {results['total_fits']}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def bayesian_optimization(self, model_class, param_space, n_trials=100):\n",
        "        \"\"\"Optuna ile Bayesian Optimization\"\"\"\n",
        "        print(\"🧠 Bayesian Optimization (Optuna) başlatılıyor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        def objective(trial):\n",
        "            # Parametreleri seç\n",
        "            params = {}\n",
        "            for param_name, param_config in param_space.items():\n",
        "                if param_config['type'] == 'int':\n",
        "                    params[param_name] = trial.suggest_int(\n",
        "                        param_name, param_config['low'], param_config['high']\n",
        "                    )\n",
        "                elif param_config['type'] == 'float':\n",
        "                    params[param_name] = trial.suggest_float(\n",
        "                        param_name, param_config['low'], param_config['high']\n",
        "                    )\n",
        "                elif param_config['type'] == 'categorical':\n",
        "                    params[param_name] = trial.suggest_categorical(\n",
        "                        param_name, param_config['choices']\n",
        "                    )\n",
        "            \n",
        "            # Model oluştur ve eğit\n",
        "            model = model_class(**params, random_state=self.random_state)\n",
        "            \n",
        "            # Cross-validation yap\n",
        "            scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                   cv=self.cv_strategy, scoring='neg_mean_squared_error')\n",
        "            return np.sqrt(-scores.mean())\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"Bayesian_Optimization\"):\n",
        "            # Optuna study oluştur\n",
        "            study = optuna.create_study(direction='minimize')\n",
        "            study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "            \n",
        "            # En iyi parametrelerle modeli eğit\n",
        "            best_model = model_class(**study.best_params, random_state=self.random_state)\n",
        "            best_model.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # Validation seti ile test et\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # Sonuçları kaydet\n",
        "            results = {\n",
        "                'method': 'BayesianOptimization',\n",
        "                'best_params': study.best_params,\n",
        "                'best_cv_score': study.best_value,\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': n_trials,\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model,\n",
        "                'study': study\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(study.best_params)\n",
        "            mlflow.log_metric(\"cv_rmse\", study.best_value)\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['BayesianOptimization'] = results\n",
        "            \n",
        "        print(f\"✅ Bayesian Optimization tamamlandı!\")\n",
        "        print(f\"🏆 En iyi CV RMSE: {study.best_value:.4f}\")\n",
        "        print(f\"📊 Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"⏱️ Süre: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"🔢 Toplam fit sayısı: {n_trials}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def compare_methods(self):\n",
        "        \"\"\"Tüm optimization yöntemlerini karşılaştır\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Henüz optimization yapılmamış!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📊 HYPERPARAMETER OPTIMIZATION KARŞILAŞTIRMASI\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        comparison_df = pd.DataFrame({\n",
        "            method: {\n",
        "                'CV RMSE': data['best_cv_score'],\n",
        "                'Val RMSE': data['val_rmse'],\n",
        "                'Val R²': data['val_r2'],\n",
        "                'Time (s)': data['time_elapsed'],\n",
        "                'Total Fits': data['total_fits'],\n",
        "                'Efficiency': data['val_rmse'] / (data['time_elapsed'] / 60)  # RMSE per minute\n",
        "            }\n",
        "            for method, data in self.results.items()\n",
        "        }).T\n",
        "        \n",
        "        print(comparison_df.round(4))\n",
        "        \n",
        "        # En iyi yöntemi bul\n",
        "        best_method = min(self.results.keys(), key=lambda x: self.results[x]['val_rmse'])\n",
        "        print(f\"\\n🏆 En iyi yöntem: {best_method}\")\n",
        "        print(f\"📊 En iyi validation RMSE: {self.results[best_method]['val_rmse']:.4f}\")\n",
        "        \n",
        "        return comparison_df, best_method\n",
        "    \n",
        "    def plot_optimization_comparison(self):\n",
        "        \"\"\"Optimization sonuçlarını görselleştir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Henüz optimization yapılmamış!\")\n",
        "            return\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        methods = list(self.results.keys())\n",
        "        cv_scores = [self.results[method]['best_cv_score'] for method in methods]\n",
        "        val_scores = [self.results[method]['val_rmse'] for method in methods]\n",
        "        times = [self.results[method]['time_elapsed'] for method in methods]\n",
        "        fits = [self.results[method]['total_fits'] for method in methods]\n",
        "        \n",
        "        # CV vs Validation RMSE\n",
        "        axes[0, 0].scatter(cv_scores, val_scores, s=100, alpha=0.7)\n",
        "        for i, method in enumerate(methods):\n",
        "            axes[0, 0].annotate(method, (cv_scores[i], val_scores[i]), \n",
        "                               xytext=(5, 5), textcoords='offset points')\n",
        "        axes[0, 0].set_xlabel('CV RMSE')\n",
        "        axes[0, 0].set_ylabel('Validation RMSE')\n",
        "        axes[0, 0].set_title('🎯 CV vs Validation Performance')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Time comparison\n",
        "        axes[0, 1].bar(methods, times, alpha=0.7)\n",
        "        axes[0, 1].set_title('⏱️ Execution Time')\n",
        "        axes[0, 1].set_ylabel('Time (seconds)')\n",
        "        plt.setp(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Efficiency (Performance per time)\n",
        "        efficiency = [val_scores[i] / (times[i] / 60) for i in range(len(methods))]\n",
        "        axes[1, 0].bar(methods, efficiency, alpha=0.7)\n",
        "        axes[1, 0].set_title('🚀 Efficiency (RMSE per minute)')\n",
        "        axes[1, 0].set_ylabel('RMSE / minute')\n",
        "        plt.setp(axes[1, 0].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Total evaluations\n",
        "        axes[1, 1].bar(methods, fits, alpha=0.7)\n",
        "        axes[1, 1].set_title('🔢 Total Model Evaluations')\n",
        "        axes[1, 1].set_ylabel('Number of fits')\n",
        "        plt.setp(axes[1, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"✅ HyperparameterOptimizer sınıfı oluşturuldu!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter optimization için örnek\n",
        "# Random Forest modeli ile karşılaştırma yapalım\n",
        "\n",
        "# Optimizer'ı başlat\n",
        "optimizer = HyperparameterOptimizer(X_train, y_train, X_val, y_val, cv_strategy=best_cv)\n",
        "\n",
        "# 1. Grid Search\n",
        "print(\"=\" * 60)\n",
        "print(\"🔍 GRID SEARCH OPTIMIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_results = optimizer.grid_search_optimization(\n",
        "    RandomForestRegressor(random_state=42), \n",
        "    rf_param_grid\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🎲 RANDOM SEARCH OPTIMIZATION\") \n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 2. Random Search\n",
        "rf_param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': [None] + list(range(5, 30)),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.1, 0.9)\n",
        "}\n",
        "\n",
        "random_results = optimizer.random_search_optimization(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    rf_param_dist,\n",
        "    n_iter=50\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🧠 BAYESIAN OPTIMIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 3. Bayesian Optimization\n",
        "rf_param_space = {\n",
        "    'n_estimators': {'type': 'int', 'low': 50, 'high': 300},\n",
        "    'max_depth': {'type': 'categorical', 'choices': [None, 5, 10, 15, 20, 25]},\n",
        "    'min_samples_split': {'type': 'int', 'low': 2, 'high': 20},\n",
        "    'min_samples_leaf': {'type': 'int', 'low': 1, 'high': 10},\n",
        "    'max_features': {'type': 'float', 'low': 0.1, 'high': 1.0}\n",
        "}\n",
        "\n",
        "bayesian_results = optimizer.bayesian_optimization(\n",
        "    RandomForestRegressor,\n",
        "    rf_param_space,\n",
        "    n_trials=50\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tüm optimization yöntemlerini karşılaştır\n",
        "comparison_df, best_optimization_method = optimizer.compare_methods()\n",
        "\n",
        "# Görselleştirme\n",
        "optimizer.plot_optimization_comparison()\n",
        "\n",
        "# En iyi modeli al\n",
        "best_model = optimizer.results[best_optimization_method]['best_model']\n",
        "print(f\"\\n🎉 En iyi model: {best_optimization_method}\")\n",
        "print(f\"📊 En iyi parametreler: {optimizer.results[best_optimization_method]['best_params']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Ensemble Methods - Model Birleştirme\n",
        "\n",
        "Ensemble yöntemleri, birden fazla modelin tahminlerini birleştirerek daha güçlü ve stabil modeller oluşturur:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EnsembleTrainer:\n",
        "    \"\"\"Ensemble model eğitimi için kapsamlı sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, random_state=42):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.random_state = random_state\n",
        "        self.base_models = {}\n",
        "        self.ensemble_models = {}\n",
        "        self.results = {}\n",
        "    \n",
        "    def create_base_models(self):\n",
        "        \"\"\"Temel modelleri oluştur\"\"\"\n",
        "        print(\"🏗️ Temel modeller oluşturuluyor...\")\n",
        "        \n",
        "        self.base_models = {\n",
        "            'rf': RandomForestRegressor(n_estimators=100, random_state=self.random_state),\n",
        "            'gb': GradientBoostingRegressor(random_state=self.random_state),\n",
        "            'extra': ExtraTreesRegressor(n_estimators=100, random_state=self.random_state),\n",
        "            'ridge': Ridge(alpha=1.0, random_state=self.random_state),\n",
        "            'lasso': Lasso(alpha=0.1, random_state=self.random_state)\n",
        "        }\n",
        "        \n",
        "        # Temel modelleri eğit ve değerlendir\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            print(f\"  • {name}: Validation RMSE = {val_rmse:.4f}\")\n",
        "        \n",
        "        print(\"✅ Temel modeller eğitildi!\")\n",
        "    \n",
        "    def create_voting_ensemble(self, weights=None):\n",
        "        \"\"\"Voting ensemble oluştur\"\"\"\n",
        "        print(\"\\n🗳️ Voting Ensemble oluşturuluyor...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        # Voting regressor oluştur\n",
        "        estimators = [(name, model) for name, model in self.base_models.items()]\n",
        "        voting_ensemble = VotingRegressor(estimators=estimators, weights=weights)\n",
        "        \n",
        "        # Eğit ve değerlendir\n",
        "        voting_ensemble.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        val_pred = voting_ensemble.predict(self.X_val)\n",
        "        test_pred = voting_ensemble.predict(self.X_test)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['voting'] = voting_ensemble\n",
        "        self.results['voting'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'weights': weights\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Voting Ensemble:\")\n",
        "        print(f\"  • Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  • Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  • Test R²: {test_r2:.4f}\")\n",
        "        \n",
        "        return voting_ensemble\n",
        "    \n",
        "    def create_stacking_ensemble(self, meta_model=None, cv_folds=5):\n",
        "        \"\"\"Stacking ensemble oluştur\"\"\"\n",
        "        print(\"\\n🏗️ Stacking Ensemble oluşturuluyor...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        if meta_model is None:\n",
        "            meta_model = Ridge(alpha=1.0, random_state=self.random_state)\n",
        "        \n",
        "        # Stacking regressor oluştur\n",
        "        estimators = [(name, model) for name, model in self.base_models.items()]\n",
        "        stacking_ensemble = StackingRegressor(\n",
        "            estimators=estimators,\n",
        "            final_estimator=meta_model,\n",
        "            cv=cv_folds,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        \n",
        "        # Eğit ve değerlendir\n",
        "        stacking_ensemble.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        val_pred = stacking_ensemble.predict(self.X_val)\n",
        "        test_pred = stacking_ensemble.predict(self.X_test)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['stacking'] = stacking_ensemble\n",
        "        self.results['stacking'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'meta_model': str(meta_model),\n",
        "            'cv_folds': cv_folds\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Stacking Ensemble:\")\n",
        "        print(f\"  • Meta model: {meta_model}\")\n",
        "        print(f\"  • Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  • Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  • Test R²: {test_r2:.4f}\")\n",
        "        \n",
        "        return stacking_ensemble\n",
        "    \n",
        "    def create_blending_ensemble(self, blend_ratio=0.3):\n",
        "        \"\"\"Blending ensemble oluştur\"\"\"\n",
        "        print(f\"\\n🎨 Blending Ensemble oluşturuluyor (blend_ratio={blend_ratio})...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        # Train seti ile blend için ayrı validation seti oluştur\n",
        "        X_blend_train, X_blend_val, y_blend_train, y_blend_val = train_test_split(\n",
        "            self.X_train, self.y_train, test_size=blend_ratio, random_state=self.random_state\n",
        "        )\n",
        "        \n",
        "        # Base modelleri blend train ile eğit\n",
        "        blend_predictions = []\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X_blend_train, y_blend_train)\n",
        "            blend_pred = model.predict(X_blend_val)\n",
        "            blend_predictions.append(blend_pred)\n",
        "        \n",
        "        # Meta features oluştur\n",
        "        meta_features = np.column_stack(blend_predictions)\n",
        "        \n",
        "        # Meta model eğit\n",
        "        meta_model = Ridge(alpha=1.0, random_state=self.random_state)\n",
        "        meta_model.fit(meta_features, y_blend_val)\n",
        "        \n",
        "        # Tüm train seti ile base modelleri yeniden eğit\n",
        "        for model in self.base_models.values():\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        # Validation ve test tahminleri\n",
        "        val_meta_features = np.column_stack([\n",
        "            model.predict(self.X_val) for model in self.base_models.values()\n",
        "        ])\n",
        "        test_meta_features = np.column_stack([\n",
        "            model.predict(self.X_test) for model in self.base_models.values()\n",
        "        ])\n",
        "        \n",
        "        val_pred = meta_model.predict(val_meta_features)\n",
        "        test_pred = meta_model.predict(test_meta_features)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['blending'] = {\n",
        "            'base_models': self.base_models,\n",
        "            'meta_model': meta_model\n",
        "        }\n",
        "        self.results['blending'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'blend_ratio': blend_ratio\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Blending Ensemble:\")\n",
        "        print(f\"  • Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  • Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  • Test R²: {test_r2:.4f}\")\n",
        "        \n",
        "        return self.ensemble_models['blending']\n",
        "    \n",
        "    def compare_ensembles(self):\n",
        "        \"\"\"Ensemble yöntemlerini karşılaştır\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Henüz ensemble oluşturulmamış!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"🏆 ENSEMBLE METHODS KARŞILAŞTIRMASI\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        # Base modellerin performansını da ekle\n",
        "        base_results = {}\n",
        "        for name, model in self.base_models.items():\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            test_pred = model.predict(self.X_test)\n",
        "            base_results[f'base_{name}'] = {\n",
        "                'val_rmse': np.sqrt(mean_squared_error(self.y_val, val_pred)),\n",
        "                'test_rmse': np.sqrt(mean_squared_error(self.y_test, test_pred)),\n",
        "                'val_r2': r2_score(self.y_val, val_pred),\n",
        "                'test_r2': r2_score(self.y_test, test_pred)\n",
        "            }\n",
        "        \n",
        "        # Tüm sonuçları birleştir\n",
        "        all_results = {**base_results, **self.results}\n",
        "        \n",
        "        comparison_df = pd.DataFrame({\n",
        "            method: {\n",
        "                'Val RMSE': data['val_rmse'],\n",
        "                'Test RMSE': data['test_rmse'],\n",
        "                'Val R²': data['val_r2'],\n",
        "                'Test R²': data['test_r2']\n",
        "            }\n",
        "            for method, data in all_results.items()\n",
        "        }).T\n",
        "        \n",
        "        comparison_df = comparison_df.sort_values('Test RMSE')\n",
        "        print(comparison_df.round(4))\n",
        "        \n",
        "        # En iyi ensemble'ı bul\n",
        "        ensemble_only = {k: v for k, v in self.results.items()}\n",
        "        best_ensemble = min(ensemble_only.keys(), key=lambda x: ensemble_only[x]['test_rmse'])\n",
        "        \n",
        "        print(f\"\\n🏆 En iyi ensemble: {best_ensemble}\")\n",
        "        print(f\"📊 Test RMSE: {ensemble_only[best_ensemble]['test_rmse']:.4f}\")\n",
        "        \n",
        "        return comparison_df, best_ensemble\n",
        "    \n",
        "    def plot_ensemble_comparison(self):\n",
        "        \"\"\"Ensemble sonuçlarını görselleştir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"❌ Henüz ensemble oluşturulmamış!\")\n",
        "            return\n",
        "        \n",
        "        # Base modellerin sonuçlarını da dahil et\n",
        "        all_models = {}\n",
        "        \n",
        "        # Base modeller\n",
        "        for name, model in self.base_models.items():\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            test_pred = model.predict(self.X_test)\n",
        "            all_models[f'Base_{name.upper()}'] = {\n",
        "                'val_rmse': np.sqrt(mean_squared_error(self.y_val, val_pred)),\n",
        "                'test_rmse': np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "            }\n",
        "        \n",
        "        # Ensemble modeller\n",
        "        for name, result in self.results.items():\n",
        "            all_models[f'Ensemble_{name.upper()}'] = {\n",
        "                'val_rmse': result['val_rmse'],\n",
        "                'test_rmse': result['test_rmse']\n",
        "            }\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # RMSE karşılaştırması\n",
        "        models = list(all_models.keys())\n",
        "        val_rmse = [all_models[model]['val_rmse'] for model in models]\n",
        "        test_rmse = [all_models[model]['test_rmse'] for model in models]\n",
        "        \n",
        "        x_pos = np.arange(len(models))\n",
        "        width = 0.35\n",
        "        \n",
        "        ax1.bar(x_pos - width/2, val_rmse, width, label='Validation RMSE', alpha=0.8)\n",
        "        ax1.bar(x_pos + width/2, test_rmse, width, label='Test RMSE', alpha=0.8)\n",
        "        ax1.set_xlabel('Models')\n",
        "        ax1.set_ylabel('RMSE')\n",
        "        ax1.set_title('📊 Model Performance Comparison')\n",
        "        ax1.set_xticks(x_pos)\n",
        "        ax1.set_xticklabels(models, rotation=45, ha='right')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Ensemble improvement\n",
        "        base_best_rmse = min([all_models[m]['test_rmse'] for m in models if m.startswith('Base_')])\n",
        "        ensemble_models = [m for m in models if m.startswith('Ensemble_')]\n",
        "        improvements = [(base_best_rmse - all_models[m]['test_rmse']) / base_best_rmse * 100 \n",
        "                       for m in ensemble_models]\n",
        "        \n",
        "        colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "        ax2.bar(range(len(ensemble_models)), improvements, color=colors, alpha=0.7)\n",
        "        ax2.set_xlabel('Ensemble Methods')\n",
        "        ax2.set_ylabel('Improvement (%)')\n",
        "        ax2.set_title('🚀 Ensemble Improvement vs Best Base Model')\n",
        "        ax2.set_xticks(range(len(ensemble_models)))\n",
        "        ax2.set_xticklabels([m.replace('Ensemble_', '') for m in ensemble_models], rotation=45, ha='right')\n",
        "        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"✅ EnsembleTrainer sınıfı oluşturuldu!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble eğitimi yapalım\n",
        "ensemble_trainer = EnsembleTrainer(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "print(\"🎯 ENSEMBLE METHODS EĞİTİMİ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Voting Ensemble\n",
        "voting_model = ensemble_trainer.create_voting_ensemble()\n",
        "\n",
        "# 2. Stacking Ensemble  \n",
        "stacking_model = ensemble_trainer.create_stacking_ensemble()\n",
        "\n",
        "# 3. Blending Ensemble\n",
        "blending_model = ensemble_trainer.create_blending_ensemble()\n",
        "\n",
        "# Tüm ensemble yöntemlerini karşılaştır\n",
        "ensemble_comparison, best_ensemble_method = ensemble_trainer.compare_ensembles()\n",
        "\n",
        "# Görselleştirme\n",
        "ensemble_trainer.plot_ensemble_comparison()\n",
        "\n",
        "print(f\"\\n🎉 En iyi ensemble method: {best_ensemble_method}\")\n",
        "print(f\"📊 En iyi test RMSE: {ensemble_trainer.results[best_ensemble_method]['test_rmse']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Learning Curves ve Model Diagnostics\n",
        "\n",
        "Model performansını daha detaylı analiz etmek için learning curves ve çeşitli diagnostics kullanacağız:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_learning_curves(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
        "    \"\"\"Learning curves çizimi\"\"\"\n",
        "    print(\"📈 Learning curves hesaplanıyor...\")\n",
        "    \n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X, y, cv=cv, train_sizes=train_sizes, \n",
        "        scoring='neg_mean_squared_error', n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # RMSE'ye çevir\n",
        "    train_rmse = np.sqrt(-train_scores)\n",
        "    val_rmse = np.sqrt(-val_scores)\n",
        "    \n",
        "    # Ortalama ve standart sapma\n",
        "    train_rmse_mean = train_rmse.mean(axis=1)\n",
        "    train_rmse_std = train_rmse.std(axis=1)\n",
        "    val_rmse_mean = val_rmse.mean(axis=1)\n",
        "    val_rmse_std = val_rmse.std(axis=1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Learning curves\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(train_sizes, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
        "    plt.fill_between(train_sizes, train_rmse_mean - train_rmse_std, \n",
        "                     train_rmse_mean + train_rmse_std, alpha=0.2, color='blue')\n",
        "    \n",
        "    plt.plot(train_sizes, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
        "    plt.fill_between(train_sizes, val_rmse_mean - val_rmse_std, \n",
        "                     val_rmse_mean + val_rmse_std, alpha=0.2, color='red')\n",
        "    \n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('📈 Learning Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Overfitting analizi\n",
        "    plt.subplot(2, 2, 2)\n",
        "    overfitting = val_rmse_mean - train_rmse_mean\n",
        "    plt.plot(train_sizes, overfitting, 'o-', color='orange')\n",
        "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('Validation RMSE - Training RMSE')\n",
        "    plt.title('⚠️ Overfitting Analysis')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Final performance\n",
        "    final_train_rmse = train_rmse_mean[-1]\n",
        "    final_val_rmse = val_rmse_mean[-1]\n",
        "    final_gap = final_val_rmse - final_train_rmse\n",
        "    \n",
        "    plt.subplot(2, 2, 3)\n",
        "    metrics = ['Training RMSE', 'Validation RMSE', 'Performance Gap']\n",
        "    values = [final_train_rmse, final_val_rmse, final_gap]\n",
        "    colors = ['blue', 'red', 'orange']\n",
        "    \n",
        "    bars = plt.bar(metrics, values, color=colors, alpha=0.7)\n",
        "    plt.title('📊 Final Performance Metrics')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                f'{value:.4f}', ha='center', va='bottom')\n",
        "    \n",
        "    # Convergence analysis\n",
        "    plt.subplot(2, 2, 4)\n",
        "    val_improvement = np.diff(val_rmse_mean)\n",
        "    plt.plot(train_sizes[1:], val_improvement, 'o-', color='green')\n",
        "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('RMSE Improvement')\n",
        "    plt.title('🎯 Validation Performance Improvement')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✅ Learning curves analizi tamamlandı!\")\n",
        "    print(f\"📊 Final training RMSE: {final_train_rmse:.4f}\")\n",
        "    print(f\"📊 Final validation RMSE: {final_val_rmse:.4f}\")\n",
        "    print(f\"⚠️ Performance gap: {final_gap:.4f}\")\n",
        "    \n",
        "    return train_sizes, train_rmse_mean, val_rmse_mean\n",
        "\n",
        "def plot_validation_curves(model, X, y, param_name, param_range, cv=5):\n",
        "    \"\"\"Validation curves çizimi\"\"\"\n",
        "    print(f\"📊 Validation curves hesaplanıyor ({param_name})...\")\n",
        "    \n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model, X, y, param_name=param_name, param_range=param_range,\n",
        "        cv=cv, scoring='neg_mean_squared_error', n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # RMSE'ye çevir\n",
        "    train_rmse = np.sqrt(-train_scores)\n",
        "    val_rmse = np.sqrt(-val_scores)\n",
        "    \n",
        "    # Ortalama ve standart sapma\n",
        "    train_rmse_mean = train_rmse.mean(axis=1)\n",
        "    train_rmse_std = train_rmse.std(axis=1)\n",
        "    val_rmse_mean = val_rmse.mean(axis=1)\n",
        "    val_rmse_std = val_rmse.std(axis=1)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    plt.plot(param_range, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
        "    plt.fill_between(param_range, train_rmse_mean - train_rmse_std, \n",
        "                     train_rmse_mean + train_rmse_std, alpha=0.2, color='blue')\n",
        "    \n",
        "    plt.plot(param_range, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
        "    plt.fill_between(param_range, val_rmse_mean - val_rmse_std, \n",
        "                     val_rmse_mean + val_rmse_std, alpha=0.2, color='red')\n",
        "    \n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title(f'📊 Validation Curve for {param_name}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # En iyi parametreyi bul\n",
        "    best_idx = np.argmin(val_rmse_mean)\n",
        "    best_param = param_range[best_idx]\n",
        "    best_score = val_rmse_mean[best_idx]\n",
        "    \n",
        "    plt.axvline(x=best_param, color='green', linestyle='--', alpha=0.7, \n",
        "                label=f'Best: {best_param} (RMSE: {best_score:.4f})')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✅ En iyi {param_name}: {best_param}\")\n",
        "    print(f\"📊 En iyi validation RMSE: {best_score:.4f}\")\n",
        "    \n",
        "    return best_param, best_score\n",
        "\n",
        "# En iyi model ile learning curves analizi\n",
        "print(\"🔍 MODEL DIAGNOSTICS VE LEARNING CURVES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Learning curves\n",
        "train_sizes, train_rmse, val_rmse = plot_learning_curves(\n",
        "    best_model, X_train, y_train, cv=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation curves - n_estimators parametresi için\n",
        "print(\"\\n📊 VALIDATION CURVES ANALİZİ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Random Forest için n_estimators validation curve\n",
        "n_estimators_range = [50, 100, 150, 200, 250, 300, 400, 500]\n",
        "best_n_estimators, best_score = plot_validation_curves(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    X_train, y_train,\n",
        "    'n_estimators',\n",
        "    n_estimators_range,\n",
        "    cv=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Model Versioning ve Experiment Tracking\n",
        "\n",
        "MLflow ile model versioning ve experiment tracking yapacağız:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelTracker:\n",
        "    \"\"\"Model versioning ve tracking için sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, experiment_name=\"Advanced_Model_Training\"):\n",
        "        self.experiment_name = experiment_name\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        self.model_registry = {}\n",
        "    \n",
        "    def log_model_experiment(self, model, model_name, X_train, y_train, X_val, y_val, \n",
        "                           X_test, y_test, hyperparams=None, model_type=\"single\"):\n",
        "        \"\"\"Model experiment'ini kaydet\"\"\"\n",
        "        \n",
        "        with mlflow.start_run(run_name=f\"{model_name}_{model_type}\"):\n",
        "            # Model eğitimi\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Tahminler\n",
        "            train_pred = model.predict(X_train)\n",
        "            val_pred = model.predict(X_val)\n",
        "            test_pred = model.predict(X_test)\n",
        "            \n",
        "            # Metrikler\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "            \n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "            \n",
        "            # MLflow'a log\n",
        "            mlflow.log_param(\"model_name\", model_name)\n",
        "            mlflow.log_param(\"model_type\", model_type)\n",
        "            mlflow.log_param(\"training_samples\", len(X_train))\n",
        "            \n",
        "            if hyperparams:\n",
        "                mlflow.log_params(hyperparams)\n",
        "            \n",
        "            mlflow.log_metric(\"train_rmse\", train_rmse)\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"test_rmse\", test_rmse)\n",
        "            mlflow.log_metric(\"train_r2\", train_r2)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"test_r2\", test_r2)\n",
        "            mlflow.log_metric(\"training_time\", training_time)\n",
        "            mlflow.log_metric(\"overfitting_score\", train_rmse - val_rmse)\n",
        "            \n",
        "            # Model'i kaydet\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "            \n",
        "            # Model registry'e ekle\n",
        "            run_id = mlflow.active_run().info.run_id\n",
        "            self.model_registry[model_name] = {\n",
        "                'run_id': run_id,\n",
        "                'model': model,\n",
        "                'metrics': {\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'val_rmse': val_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'test_r2': test_r2\n",
        "                },\n",
        "                'training_time': training_time,\n",
        "                'timestamp': datetime.now()\n",
        "            }\n",
        "            \n",
        "            print(f\"✅ {model_name} logged to MLflow (Run ID: {run_id})\")\n",
        "            print(f\"   📊 Test RMSE: {test_rmse:.4f}, Test R²: {test_r2:.4f}\")\n",
        "            \n",
        "            return run_id\n",
        "    \n",
        "    def register_best_model(self, model_name=\"BestModel\"):\n",
        "        \"\"\"En iyi modeli registry'e kaydet\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"❌ Kayıtlı model yok!\")\n",
        "            return\n",
        "        \n",
        "        # En iyi modeli bul\n",
        "        best_model_name = min(self.model_registry.keys(), \n",
        "                             key=lambda x: self.model_registry[x]['metrics']['test_rmse'])\n",
        "        \n",
        "        best_model_info = self.model_registry[best_model_name]\n",
        "        \n",
        "        # Model registry'e kaydet\n",
        "        model_uri = f\"runs:/{best_model_info['run_id']}/model\"\n",
        "        \n",
        "        try:\n",
        "            mlflow.register_model(\n",
        "                model_uri=model_uri,\n",
        "                name=model_name\n",
        "            )\n",
        "            print(f\"🏆 En iyi model '{model_name}' olarak registry'e kaydedildi!\")\n",
        "            print(f\"📊 Model: {best_model_name}\")\n",
        "            print(f\"📊 Test RMSE: {best_model_info['metrics']['test_rmse']:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Model registry'e kaydedilemedi: {e}\")\n",
        "        \n",
        "        return best_model_name, best_model_info\n",
        "    \n",
        "    def compare_all_models(self):\n",
        "        \"\"\"Tüm kayıtlı modelleri karşılaştır\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"❌ Kayıtlı model yok!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"📊 TÜM MODEL KARŞILAŞTIRMASI\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        comparison_data = []\n",
        "        for name, info in self.model_registry.items():\n",
        "            comparison_data.append({\n",
        "                'Model': name,\n",
        "                'Test RMSE': info['metrics']['test_rmse'],\n",
        "                'Test R²': info['metrics']['test_r2'],\n",
        "                'Val RMSE': info['metrics']['val_rmse'],\n",
        "                'Training Time (s)': info['training_time'],\n",
        "                'Timestamp': info['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "        \n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.sort_values('Test RMSE')\n",
        "        print(comparison_df.to_string(index=False))\n",
        "        \n",
        "        return comparison_df\n",
        "    \n",
        "    def plot_model_comparison(self):\n",
        "        \"\"\"Model karşılaştırma grafiği\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"❌ Kayıtlı model yok!\")\n",
        "            return\n",
        "        \n",
        "        models = list(self.model_registry.keys())\n",
        "        test_rmse = [self.model_registry[m]['metrics']['test_rmse'] for m in models]\n",
        "        test_r2 = [self.model_registry[m]['metrics']['test_r2'] for m in models]\n",
        "        training_times = [self.model_registry[m]['training_time'] for m in models]\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Test RMSE comparison\n",
        "        axes[0, 0].barh(models, test_rmse, alpha=0.7)\n",
        "        axes[0, 0].set_xlabel('Test RMSE')\n",
        "        axes[0, 0].set_title('🎯 Test RMSE Comparison')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Test R² comparison\n",
        "        axes[0, 1].barh(models, test_r2, alpha=0.7, color='green')\n",
        "        axes[0, 1].set_xlabel('Test R²')\n",
        "        axes[0, 1].set_title('📊 Test R² Comparison')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Training time comparison\n",
        "        axes[1, 0].barh(models, training_times, alpha=0.7, color='orange')\n",
        "        axes[1, 0].set_xlabel('Training Time (seconds)')\n",
        "        axes[1, 0].set_title('⏱️ Training Time Comparison')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Performance vs Time scatter\n",
        "        axes[1, 1].scatter(training_times, test_rmse, s=100, alpha=0.7, c=test_r2, cmap='viridis')\n",
        "        for i, model in enumerate(models):\n",
        "            axes[1, 1].annotate(model, (training_times[i], test_rmse[i]), \n",
        "                               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "        axes[1, 1].set_xlabel('Training Time (seconds)')\n",
        "        axes[1, 1].set_ylabel('Test RMSE')\n",
        "        axes[1, 1].set_title('🚀 Performance vs Training Time')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Model tracker'ı başlat\n",
        "tracker = ModelTracker(\"Advanced_Model_Training_Final\")\n",
        "\n",
        "print(\"📝 MODEL TRACKING VE VERSIONING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# En iyi hyperparameter optimization modelini kaydet\n",
        "if 'best_model' in locals():\n",
        "    tracker.log_model_experiment(\n",
        "        best_model, \n",
        "        f\"Optimized_{best_optimization_method}\",\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "        hyperparams=optimizer.results[best_optimization_method]['best_params'],\n",
        "        model_type=\"optimized\"\n",
        "    )\n",
        "\n",
        "# En iyi ensemble modelini kaydet\n",
        "if 'ensemble_trainer' in locals():\n",
        "    best_ensemble_model = ensemble_trainer.ensemble_models[best_ensemble_method]\n",
        "    if best_ensemble_method == 'blending':\n",
        "        # Blending için özel işlem gerekli\n",
        "        print(f\"⚠️ Blending model complex structure - logging metadata only\")\n",
        "    else:\n",
        "        tracker.log_model_experiment(\n",
        "            best_ensemble_model,\n",
        "            f\"Ensemble_{best_ensemble_method}\",\n",
        "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "            model_type=\"ensemble\"\n",
        "        )\n",
        "\n",
        "# Baseline modelleri kaydet\n",
        "baseline_models = {\n",
        "    'RandomForest_Baseline': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting_Baseline': GradientBoostingRegressor(random_state=42),\n",
        "    'Ridge_Baseline': Ridge(alpha=1.0, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in baseline_models.items():\n",
        "    tracker.log_model_experiment(\n",
        "        model, name, X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "        model_type=\"baseline\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tüm modelleri karşılaştır\n",
        "final_comparison = tracker.compare_all_models()\n",
        "\n",
        "# En iyi modeli registry'e kaydet\n",
        "best_model_name, best_model_info = tracker.register_best_model(\"California_Housing_Best_Model\")\n",
        "\n",
        "# Görselleştirme\n",
        "tracker.plot_model_comparison()\n",
        "\n",
        "print(f\"\\n🎉 Model training süreci tamamlandı!\")\n",
        "print(f\"🏆 En iyi model: {best_model_name}\")\n",
        "print(f\"📊 Final test RMSE: {best_model_info['metrics']['test_rmse']:.4f}\")\n",
        "print(f\"📊 Final test R²: {best_model_info['metrics']['test_r2']:.4f}\")\n",
        "print(f\"⏱️ Training time: {best_model_info['training_time']:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Özet ve Sonuçlar\n",
        "\n",
        "### 🎯 Bu Bölümde Neler Öğrendik?\n",
        "\n",
        "1. **Advanced Cross-Validation**: Farklı CV stratejilerini karşılaştırdık\n",
        "2. **Hyperparameter Optimization**: Grid Search, Random Search ve Bayesian Optimization\n",
        "3. **Ensemble Methods**: Voting, Stacking ve Blending teknikleri\n",
        "4. **Model Diagnostics**: Learning curves ve validation curves\n",
        "5. **Model Tracking**: MLflow ile experiment tracking ve versioning\n",
        "\n",
        "### 📊 Ana Bulgular:\n",
        "\n",
        "- **En İyi Optimization Yöntemi**: Bayesian optimization genellikle en etkili\n",
        "- **Ensemble Avantajı**: Tek modellere göre %5-15 performans artışı\n",
        "- **Training Efficiency**: Random search, grid search'ten çok daha hızlı\n",
        "- **Model Stability**: Cross-validation ile daha güvenilir sonuçlar\n",
        "\n",
        "### 🚀 Sonraki Adımlar:\n",
        "\n",
        "1. **Model Deployment**: En iyi modeli production ortamına alma\n",
        "2. **Monitoring**: Model performansını sürekli izleme\n",
        "3. **A/B Testing**: Farklı model versiyonlarını test etme\n",
        "4. **Automation**: Pipeline'ların otomasyonu\n",
        "\n",
        "### 💡 İpuçları:\n",
        "\n",
        "- Her zaman baseline modeller ile karşılaştırın\n",
        "- Overfitting için learning curves'u kontrol edin\n",
        "- Ensemble yöntemleri denemeyi unutmayın\n",
        "- Experiment tracking kullanarak sonuçları kaydedin\n",
        "- Cross-validation stratejisini data tipine göre seçin\n",
        "\n",
        "---\n",
        "\n",
        "**Level 4 Tamamlandı! 🎉**\n",
        "\n",
        "Artık advanced model training tekniklerini kullanarak yüksek performanslı modeller geliştirebilirsiniz!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
