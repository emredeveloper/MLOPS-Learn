{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Level 4: Model Training - Model EÄŸitimi\n",
        "\n",
        "## ğŸ¯ Bu BÃ¶lÃ¼mde Ã–ÄŸrenecekleriniz:\n",
        "- Advanced model training stratejileri\n",
        "- Hyperparameter optimization (GridSearch, RandomSearch, Bayesian)\n",
        "- Cross-validation ve validation stratejileri\n",
        "- Ensemble methods ve stacking\n",
        "- Model regularization teknikleri\n",
        "- Early stopping ve learning curves\n",
        "- Distributed training\n",
        "- Model versioning ve experiment tracking\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Model Training Nedir?\n",
        "\n",
        "**Model Training**, makine Ã¶ÄŸrenmesi modellerinin performansÄ±nÄ± maksimize etmek iÃ§in kapsamlÄ± eÄŸitim stratejilerinin uygulandÄ±ÄŸÄ± kritik aÅŸamadÄ±r.\n",
        "\n",
        "### ğŸ§  Advanced Model Training AÅŸamalarÄ±:\n",
        "1. **Training Strategy Design**: EÄŸitim stratejisi tasarlama\n",
        "2. **Hyperparameter Optimization**: Optimal parametreleri bulma\n",
        "3. **Validation Strategy**: DoÄŸrulama stratejisi belirleme\n",
        "4. **Ensemble Methods**: Birden fazla modeli birleÅŸtirme\n",
        "5. **Regularization**: Overfitting'i Ã¶nleme\n",
        "6. **Model Selection**: En iyi modeli seÃ§me\n",
        "7. **Performance Monitoring**: EÄŸitim sÃ¼recini izleme\n",
        "\n",
        "### ğŸ¯ Neden Advanced Model Training?\n",
        "- **Maximum Performance**: Model performansÄ±nÄ± maksimize etme\n",
        "- **Robust Models**: Genelleme yeteneÄŸi yÃ¼ksek modeller\n",
        "- **Efficient Training**: Kaynak-verimli eÄŸitim sÃ¼reÃ§leri\n",
        "- **Scalability**: BÃ¼yÃ¼k veri setleri ile Ã§alÄ±ÅŸabilme\n",
        "- **Production Ready**: Ãœretim ortamÄ±na hazÄ±r modeller\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri import edelim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, \n",
        "    StratifiedKFold, KFold, TimeSeriesSplit, learning_curve, validation_curve\n",
        ")\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor,\n",
        "    VotingRegressor, StackingRegressor, BaggingRegressor\n",
        ")\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from scipy.stats import uniform, randint\n",
        "import optuna\n",
        "from itertools import combinations\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"ğŸ“¦ TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")\n",
        "print(\"ğŸš€ Advanced Model Training eÄŸitimine hazÄ±rÄ±z!\")\n",
        "print(f\"ğŸ“… BaÅŸlangÄ±Ã§ zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Veri Seti HazÄ±rlama ve MLflow Setup\n",
        "\n",
        "Advanced model training sÃ¼recini gÃ¶stermek iÃ§in California housing veri setini kullanacaÄŸÄ±z ve MLflow ile experiment tracking yapacaÄŸÄ±z:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MLflow experiment setup\n",
        "mlflow.set_experiment(\"Advanced_Model_Training\")\n",
        "\n",
        "# California housing veri setini yÃ¼kleyelim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Veri setini yÃ¼kle\n",
        "california_housing = fetch_california_housing()\n",
        "X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "y = california_housing.target\n",
        "\n",
        "print(\"ğŸ  California Housing Veri Seti YÃ¼klendi!\")\n",
        "print(f\"ğŸ“Š Veri boyutu: {X.shape}\")\n",
        "print(f\"ğŸ¯ Hedef deÄŸiÅŸken: Ev fiyatlarÄ± (hundreds of thousands of dollars)\")\n",
        "\n",
        "# Veri setini train, validation, test olarak bÃ¶lelim\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"\\nğŸ“Š Veri seti bÃ¶lÃ¼mÃ¼:\")\n",
        "print(f\"  â€¢ Training: {X_train.shape[0]} sample ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  â€¢ Validation: {X_val.shape[0]} sample ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  â€¢ Test: {X_test.shape[0]} sample ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "# Veri Ã¶n-iÅŸleme\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nâœ… Veri Ã¶n-iÅŸleme tamamlandÄ±!\")\n",
        "print(f\"ğŸ¯ MLflow experiment: {mlflow.get_experiment_by_name('Advanced_Model_Training').experiment_id}\")\n",
        "\n",
        "# Temel istatistikler\n",
        "print(f\"\\nğŸ“ˆ Hedef deÄŸiÅŸken istatistikleri:\")\n",
        "print(f\"  Training - Ortalama: ${y_train.mean():.2f}00k, Std: ${y_train.std():.2f}00k\")\n",
        "print(f\"  Validation - Ortalama: ${y_val.mean():.2f}00k, Std: ${y_val.std():.2f}00k\")\n",
        "print(f\"  Test - Ortalama: ${y_test.mean():.2f}00k, Std: ${y_test.std():.2f}00k\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Advanced Training Strategies\n",
        "\n",
        "### 3.1 Cross-Validation Stratejileri\n",
        "\n",
        "FarklÄ± cross-validation stratejilerini karÅŸÄ±laÅŸtÄ±ralÄ±m:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrossValidationAnalyzer:\n",
        "    \"\"\"Cross-validation stratejilerini analiz eden sÄ±nÄ±f\"\"\"\n",
        "    \n",
        "    def __init__(self, X, y, random_state=42):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.random_state = random_state\n",
        "        self.results = {}\n",
        "    \n",
        "    def compare_cv_strategies(self, model, n_splits=5):\n",
        "        \"\"\"FarklÄ± CV stratejilerini karÅŸÄ±laÅŸtÄ±r\"\"\"\n",
        "        \n",
        "        # FarklÄ± CV stratejileri\n",
        "        cv_strategies = {\n",
        "            'KFold': KFold(n_splits=n_splits, shuffle=True, random_state=self.random_state),\n",
        "            'KFold (No Shuffle)': KFold(n_splits=n_splits, shuffle=False),\n",
        "        }\n",
        "        \n",
        "        print(\"ğŸ”„ Cross-validation stratejileri karÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor...\\n\")\n",
        "        \n",
        "        for name, cv_strategy in cv_strategies.items():\n",
        "            scores = cross_val_score(model, self.X, self.y, cv=cv_strategy, \n",
        "                                   scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "            rmse_scores = np.sqrt(-scores)\n",
        "            \n",
        "            self.results[name] = {\n",
        "                'mean_rmse': rmse_scores.mean(),\n",
        "                'std_rmse': rmse_scores.std(),\n",
        "                'scores': rmse_scores,\n",
        "                'cv_object': cv_strategy\n",
        "            }\n",
        "            \n",
        "            print(f\"ğŸ“Š {name}:\")\n",
        "            print(f\"  â€¢ Mean RMSE: {rmse_scores.mean():.4f} Â± {rmse_scores.std():.4f}\")\n",
        "            print(f\"  â€¢ Score range: [{rmse_scores.min():.4f}, {rmse_scores.max():.4f}]\")\n",
        "            print()\n",
        "    \n",
        "    def plot_cv_comparison(self):\n",
        "        \"\"\"CV sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ Ã–nce CV analizi yapÄ±n!\")\n",
        "            return\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Box plot\n",
        "        data_for_box = [self.results[name]['scores'] for name in self.results.keys()]\n",
        "        labels = list(self.results.keys())\n",
        "        \n",
        "        ax1.boxplot(data_for_box, labels=labels)\n",
        "        ax1.set_title('ğŸ“Š Cross-Validation RMSE DaÄŸÄ±lÄ±mÄ±')\n",
        "        ax1.set_ylabel('RMSE')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Mean Â± Std plot\n",
        "        means = [self.results[name]['mean_rmse'] for name in self.results.keys()]\n",
        "        stds = [self.results[name]['std_rmse'] for name in self.results.keys()]\n",
        "        \n",
        "        x_pos = np.arange(len(labels))\n",
        "        ax2.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)\n",
        "        ax2.set_title('ğŸ“ˆ Cross-Validation Ortalama RMSE')\n",
        "        ax2.set_ylabel('RMSE')\n",
        "        ax2.set_xticks(x_pos)\n",
        "        ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def get_best_cv_strategy(self):\n",
        "        \"\"\"En iyi CV stratejisini bul\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ Ã–nce CV analizi yapÄ±n!\")\n",
        "            return None\n",
        "        \n",
        "        best_strategy = min(self.results.keys(), \n",
        "                          key=lambda x: self.results[x]['mean_rmse'])\n",
        "        \n",
        "        print(f\"ğŸ† En iyi CV stratejisi: {best_strategy}\")\n",
        "        print(f\"ğŸ“Š Mean RMSE: {self.results[best_strategy]['mean_rmse']:.4f}\")\n",
        "        \n",
        "        return best_strategy, self.results[best_strategy]['cv_object']\n",
        "\n",
        "# Test modeli ile CV analizi yapalÄ±m\n",
        "test_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "cv_analyzer = CrossValidationAnalyzer(X_train, y_train)\n",
        "\n",
        "# CV stratejilerini karÅŸÄ±laÅŸtÄ±r\n",
        "cv_analyzer.compare_cv_strategies(test_model, n_splits=5)\n",
        "\n",
        "# SonuÃ§larÄ± gÃ¶rselleÅŸtir\n",
        "cv_analyzer.plot_cv_comparison()\n",
        "\n",
        "# En iyi stratejiyi bul\n",
        "best_cv_name, best_cv = cv_analyzer.get_best_cv_strategy()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.2 Hyperparameter Optimization\n",
        "\n",
        "Hyperparameter optimization iÃ§in Ã¼Ã§ farklÄ± yaklaÅŸÄ±mÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z:\n",
        "1. **Grid Search**: TÃ¼m kombinasyonlarÄ± dener\n",
        "2. **Random Search**: Rastgele parametre kombinasyonlarÄ±\n",
        "3. **Bayesian Optimization**: AkÄ±llÄ± parametre seÃ§imi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyperparameterOptimizer:\n",
        "    \"\"\"Hyperparameter optimization iÃ§in kapsamlÄ± sÄ±nÄ±f\"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, X_val, y_val, cv_strategy=None, random_state=42):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.cv_strategy = cv_strategy or KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "        self.random_state = random_state\n",
        "        self.results = {}\n",
        "    \n",
        "    def grid_search_optimization(self, model, param_grid, scoring='neg_mean_squared_error'):\n",
        "        \"\"\"Grid Search ile hyperparameter optimization\"\"\"\n",
        "        print(\"ğŸ” Grid Search baÅŸlatÄ±lÄ±yor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"GridSearch_Optimization\"):\n",
        "            grid_search = GridSearchCV(\n",
        "                model, param_grid, cv=self.cv_strategy, \n",
        "                scoring=scoring, n_jobs=-1, verbose=1\n",
        "            )\n",
        "            \n",
        "            grid_search.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # En iyi modeli validation seti ile test et\n",
        "            best_model = grid_search.best_estimator_\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # SonuÃ§larÄ± kaydet\n",
        "            results = {\n",
        "                'method': 'GridSearch',\n",
        "                'best_params': grid_search.best_params_,\n",
        "                'best_cv_score': np.sqrt(-grid_search.best_score_),\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': len(grid_search.cv_results_['params']),\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(grid_search.best_params_)\n",
        "            mlflow.log_metric(\"cv_rmse\", results['best_cv_score'])\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['GridSearch'] = results\n",
        "            \n",
        "        print(f\"âœ… Grid Search tamamlandÄ±!\")\n",
        "        print(f\"ğŸ† En iyi CV RMSE: {results['best_cv_score']:.4f}\")\n",
        "        print(f\"ğŸ“Š Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"â±ï¸ SÃ¼re: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"ğŸ”¢ Toplam fit sayÄ±sÄ±: {results['total_fits']}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def random_search_optimization(self, model, param_distributions, n_iter=100, scoring='neg_mean_squared_error'):\n",
        "        \"\"\"Random Search ile hyperparameter optimization\"\"\"\n",
        "        print(\"ğŸ² Random Search baÅŸlatÄ±lÄ±yor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"RandomSearch_Optimization\"):\n",
        "            random_search = RandomizedSearchCV(\n",
        "                model, param_distributions, n_iter=n_iter, cv=self.cv_strategy,\n",
        "                scoring=scoring, n_jobs=-1, random_state=self.random_state, verbose=1\n",
        "            )\n",
        "            \n",
        "            random_search.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # En iyi modeli validation seti ile test et\n",
        "            best_model = random_search.best_estimator_\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # SonuÃ§larÄ± kaydet\n",
        "            results = {\n",
        "                'method': 'RandomSearch',\n",
        "                'best_params': random_search.best_params_,\n",
        "                'best_cv_score': np.sqrt(-random_search.best_score_),\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': n_iter,\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(random_search.best_params_)\n",
        "            mlflow.log_metric(\"cv_rmse\", results['best_cv_score'])\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['RandomSearch'] = results\n",
        "            \n",
        "        print(f\"âœ… Random Search tamamlandÄ±!\")\n",
        "        print(f\"ğŸ† En iyi CV RMSE: {results['best_cv_score']:.4f}\")\n",
        "        print(f\"ğŸ“Š Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"â±ï¸ SÃ¼re: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"ğŸ”¢ Toplam fit sayÄ±sÄ±: {results['total_fits']}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def bayesian_optimization(self, model_class, param_space, n_trials=100):\n",
        "        \"\"\"Optuna ile Bayesian Optimization\"\"\"\n",
        "        print(\"ğŸ§  Bayesian Optimization (Optuna) baÅŸlatÄ±lÄ±yor...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        def objective(trial):\n",
        "            # Parametreleri seÃ§\n",
        "            params = {}\n",
        "            for param_name, param_config in param_space.items():\n",
        "                if param_config['type'] == 'int':\n",
        "                    params[param_name] = trial.suggest_int(\n",
        "                        param_name, param_config['low'], param_config['high']\n",
        "                    )\n",
        "                elif param_config['type'] == 'float':\n",
        "                    params[param_name] = trial.suggest_float(\n",
        "                        param_name, param_config['low'], param_config['high']\n",
        "                    )\n",
        "                elif param_config['type'] == 'categorical':\n",
        "                    params[param_name] = trial.suggest_categorical(\n",
        "                        param_name, param_config['choices']\n",
        "                    )\n",
        "            \n",
        "            # Model oluÅŸtur ve eÄŸit\n",
        "            model = model_class(**params, random_state=self.random_state)\n",
        "            \n",
        "            # Cross-validation yap\n",
        "            scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                   cv=self.cv_strategy, scoring='neg_mean_squared_error')\n",
        "            return np.sqrt(-scores.mean())\n",
        "        \n",
        "        with mlflow.start_run(run_name=\"Bayesian_Optimization\"):\n",
        "            # Optuna study oluÅŸtur\n",
        "            study = optuna.create_study(direction='minimize')\n",
        "            study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "            \n",
        "            # En iyi parametrelerle modeli eÄŸit\n",
        "            best_model = model_class(**study.best_params, random_state=self.random_state)\n",
        "            best_model.fit(self.X_train, self.y_train)\n",
        "            \n",
        "            # Validation seti ile test et\n",
        "            val_pred = best_model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            val_r2 = r2_score(self.y_val, val_pred)\n",
        "            \n",
        "            # SonuÃ§larÄ± kaydet\n",
        "            results = {\n",
        "                'method': 'BayesianOptimization',\n",
        "                'best_params': study.best_params,\n",
        "                'best_cv_score': study.best_value,\n",
        "                'val_rmse': val_rmse,\n",
        "                'val_r2': val_r2,\n",
        "                'total_fits': n_trials,\n",
        "                'time_elapsed': time.time() - start_time,\n",
        "                'best_model': best_model,\n",
        "                'study': study\n",
        "            }\n",
        "            \n",
        "            # MLflow'a kaydet\n",
        "            mlflow.log_params(study.best_params)\n",
        "            mlflow.log_metric(\"cv_rmse\", study.best_value)\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"time_elapsed\", results['time_elapsed'])\n",
        "            mlflow.sklearn.log_model(best_model, \"model\")\n",
        "            \n",
        "            self.results['BayesianOptimization'] = results\n",
        "            \n",
        "        print(f\"âœ… Bayesian Optimization tamamlandÄ±!\")\n",
        "        print(f\"ğŸ† En iyi CV RMSE: {study.best_value:.4f}\")\n",
        "        print(f\"ğŸ“Š Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"â±ï¸ SÃ¼re: {results['time_elapsed']:.2f} saniye\")\n",
        "        print(f\"ğŸ”¢ Toplam fit sayÄ±sÄ±: {n_trials}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def compare_methods(self):\n",
        "        \"\"\"TÃ¼m optimization yÃ¶ntemlerini karÅŸÄ±laÅŸtÄ±r\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ HenÃ¼z optimization yapÄ±lmamÄ±ÅŸ!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ“Š HYPERPARAMETER OPTIMIZATION KARÅILAÅTIRMASI\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        comparison_df = pd.DataFrame({\n",
        "            method: {\n",
        "                'CV RMSE': data['best_cv_score'],\n",
        "                'Val RMSE': data['val_rmse'],\n",
        "                'Val RÂ²': data['val_r2'],\n",
        "                'Time (s)': data['time_elapsed'],\n",
        "                'Total Fits': data['total_fits'],\n",
        "                'Efficiency': data['val_rmse'] / (data['time_elapsed'] / 60)  # RMSE per minute\n",
        "            }\n",
        "            for method, data in self.results.items()\n",
        "        }).T\n",
        "        \n",
        "        print(comparison_df.round(4))\n",
        "        \n",
        "        # En iyi yÃ¶ntemi bul\n",
        "        best_method = min(self.results.keys(), key=lambda x: self.results[x]['val_rmse'])\n",
        "        print(f\"\\nğŸ† En iyi yÃ¶ntem: {best_method}\")\n",
        "        print(f\"ğŸ“Š En iyi validation RMSE: {self.results[best_method]['val_rmse']:.4f}\")\n",
        "        \n",
        "        return comparison_df, best_method\n",
        "    \n",
        "    def plot_optimization_comparison(self):\n",
        "        \"\"\"Optimization sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ HenÃ¼z optimization yapÄ±lmamÄ±ÅŸ!\")\n",
        "            return\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        methods = list(self.results.keys())\n",
        "        cv_scores = [self.results[method]['best_cv_score'] for method in methods]\n",
        "        val_scores = [self.results[method]['val_rmse'] for method in methods]\n",
        "        times = [self.results[method]['time_elapsed'] for method in methods]\n",
        "        fits = [self.results[method]['total_fits'] for method in methods]\n",
        "        \n",
        "        # CV vs Validation RMSE\n",
        "        axes[0, 0].scatter(cv_scores, val_scores, s=100, alpha=0.7)\n",
        "        for i, method in enumerate(methods):\n",
        "            axes[0, 0].annotate(method, (cv_scores[i], val_scores[i]), \n",
        "                               xytext=(5, 5), textcoords='offset points')\n",
        "        axes[0, 0].set_xlabel('CV RMSE')\n",
        "        axes[0, 0].set_ylabel('Validation RMSE')\n",
        "        axes[0, 0].set_title('ğŸ¯ CV vs Validation Performance')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Time comparison\n",
        "        axes[0, 1].bar(methods, times, alpha=0.7)\n",
        "        axes[0, 1].set_title('â±ï¸ Execution Time')\n",
        "        axes[0, 1].set_ylabel('Time (seconds)')\n",
        "        plt.setp(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Efficiency (Performance per time)\n",
        "        efficiency = [val_scores[i] / (times[i] / 60) for i in range(len(methods))]\n",
        "        axes[1, 0].bar(methods, efficiency, alpha=0.7)\n",
        "        axes[1, 0].set_title('ğŸš€ Efficiency (RMSE per minute)')\n",
        "        axes[1, 0].set_ylabel('RMSE / minute')\n",
        "        plt.setp(axes[1, 0].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Total evaluations\n",
        "        axes[1, 1].bar(methods, fits, alpha=0.7)\n",
        "        axes[1, 1].set_title('ğŸ”¢ Total Model Evaluations')\n",
        "        axes[1, 1].set_ylabel('Number of fits')\n",
        "        plt.setp(axes[1, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"âœ… HyperparameterOptimizer sÄ±nÄ±fÄ± oluÅŸturuldu!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter optimization iÃ§in Ã¶rnek\n",
        "# Random Forest modeli ile karÅŸÄ±laÅŸtÄ±rma yapalÄ±m\n",
        "\n",
        "# Optimizer'Ä± baÅŸlat\n",
        "optimizer = HyperparameterOptimizer(X_train, y_train, X_val, y_val, cv_strategy=best_cv)\n",
        "\n",
        "# 1. Grid Search\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ” GRID SEARCH OPTIMIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_results = optimizer.grid_search_optimization(\n",
        "    RandomForestRegressor(random_state=42), \n",
        "    rf_param_grid\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ² RANDOM SEARCH OPTIMIZATION\") \n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 2. Random Search\n",
        "rf_param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': [None] + list(range(5, 30)),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.1, 0.9)\n",
        "}\n",
        "\n",
        "random_results = optimizer.random_search_optimization(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    rf_param_dist,\n",
        "    n_iter=50\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ§  BAYESIAN OPTIMIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 3. Bayesian Optimization\n",
        "rf_param_space = {\n",
        "    'n_estimators': {'type': 'int', 'low': 50, 'high': 300},\n",
        "    'max_depth': {'type': 'categorical', 'choices': [None, 5, 10, 15, 20, 25]},\n",
        "    'min_samples_split': {'type': 'int', 'low': 2, 'high': 20},\n",
        "    'min_samples_leaf': {'type': 'int', 'low': 1, 'high': 10},\n",
        "    'max_features': {'type': 'float', 'low': 0.1, 'high': 1.0}\n",
        "}\n",
        "\n",
        "bayesian_results = optimizer.bayesian_optimization(\n",
        "    RandomForestRegressor,\n",
        "    rf_param_space,\n",
        "    n_trials=50\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ¼m optimization yÃ¶ntemlerini karÅŸÄ±laÅŸtÄ±r\n",
        "comparison_df, best_optimization_method = optimizer.compare_methods()\n",
        "\n",
        "# GÃ¶rselleÅŸtirme\n",
        "optimizer.plot_optimization_comparison()\n",
        "\n",
        "# En iyi modeli al\n",
        "best_model = optimizer.results[best_optimization_method]['best_model']\n",
        "print(f\"\\nğŸ‰ En iyi model: {best_optimization_method}\")\n",
        "print(f\"ğŸ“Š En iyi parametreler: {optimizer.results[best_optimization_method]['best_params']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Ensemble Methods - Model BirleÅŸtirme\n",
        "\n",
        "Ensemble yÃ¶ntemleri, birden fazla modelin tahminlerini birleÅŸtirerek daha gÃ¼Ã§lÃ¼ ve stabil modeller oluÅŸturur:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EnsembleTrainer:\n",
        "    \"\"\"Ensemble model eÄŸitimi iÃ§in kapsamlÄ± sÄ±nÄ±f\"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, random_state=42):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.random_state = random_state\n",
        "        self.base_models = {}\n",
        "        self.ensemble_models = {}\n",
        "        self.results = {}\n",
        "    \n",
        "    def create_base_models(self):\n",
        "        \"\"\"Temel modelleri oluÅŸtur\"\"\"\n",
        "        print(\"ğŸ—ï¸ Temel modeller oluÅŸturuluyor...\")\n",
        "        \n",
        "        self.base_models = {\n",
        "            'rf': RandomForestRegressor(n_estimators=100, random_state=self.random_state),\n",
        "            'gb': GradientBoostingRegressor(random_state=self.random_state),\n",
        "            'extra': ExtraTreesRegressor(n_estimators=100, random_state=self.random_state),\n",
        "            'ridge': Ridge(alpha=1.0, random_state=self.random_state),\n",
        "            'lasso': Lasso(alpha=0.1, random_state=self.random_state)\n",
        "        }\n",
        "        \n",
        "        # Temel modelleri eÄŸit ve deÄŸerlendir\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "            print(f\"  â€¢ {name}: Validation RMSE = {val_rmse:.4f}\")\n",
        "        \n",
        "        print(\"âœ… Temel modeller eÄŸitildi!\")\n",
        "    \n",
        "    def create_voting_ensemble(self, weights=None):\n",
        "        \"\"\"Voting ensemble oluÅŸtur\"\"\"\n",
        "        print(\"\\nğŸ—³ï¸ Voting Ensemble oluÅŸturuluyor...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        # Voting regressor oluÅŸtur\n",
        "        estimators = [(name, model) for name, model in self.base_models.items()]\n",
        "        voting_ensemble = VotingRegressor(estimators=estimators, weights=weights)\n",
        "        \n",
        "        # EÄŸit ve deÄŸerlendir\n",
        "        voting_ensemble.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        val_pred = voting_ensemble.predict(self.X_val)\n",
        "        test_pred = voting_ensemble.predict(self.X_test)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['voting'] = voting_ensemble\n",
        "        self.results['voting'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'weights': weights\n",
        "        }\n",
        "        \n",
        "        print(f\"âœ… Voting Ensemble:\")\n",
        "        print(f\"  â€¢ Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RÂ²: {test_r2:.4f}\")\n",
        "        \n",
        "        return voting_ensemble\n",
        "    \n",
        "    def create_stacking_ensemble(self, meta_model=None, cv_folds=5):\n",
        "        \"\"\"Stacking ensemble oluÅŸtur\"\"\"\n",
        "        print(\"\\nğŸ—ï¸ Stacking Ensemble oluÅŸturuluyor...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        if meta_model is None:\n",
        "            meta_model = Ridge(alpha=1.0, random_state=self.random_state)\n",
        "        \n",
        "        # Stacking regressor oluÅŸtur\n",
        "        estimators = [(name, model) for name, model in self.base_models.items()]\n",
        "        stacking_ensemble = StackingRegressor(\n",
        "            estimators=estimators,\n",
        "            final_estimator=meta_model,\n",
        "            cv=cv_folds,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        \n",
        "        # EÄŸit ve deÄŸerlendir\n",
        "        stacking_ensemble.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        val_pred = stacking_ensemble.predict(self.X_val)\n",
        "        test_pred = stacking_ensemble.predict(self.X_test)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['stacking'] = stacking_ensemble\n",
        "        self.results['stacking'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'meta_model': str(meta_model),\n",
        "            'cv_folds': cv_folds\n",
        "        }\n",
        "        \n",
        "        print(f\"âœ… Stacking Ensemble:\")\n",
        "        print(f\"  â€¢ Meta model: {meta_model}\")\n",
        "        print(f\"  â€¢ Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RÂ²: {test_r2:.4f}\")\n",
        "        \n",
        "        return stacking_ensemble\n",
        "    \n",
        "    def create_blending_ensemble(self, blend_ratio=0.3):\n",
        "        \"\"\"Blending ensemble oluÅŸtur\"\"\"\n",
        "        print(f\"\\nğŸ¨ Blending Ensemble oluÅŸturuluyor (blend_ratio={blend_ratio})...\")\n",
        "        \n",
        "        if not self.base_models:\n",
        "            self.create_base_models()\n",
        "        \n",
        "        # Train seti ile blend iÃ§in ayrÄ± validation seti oluÅŸtur\n",
        "        X_blend_train, X_blend_val, y_blend_train, y_blend_val = train_test_split(\n",
        "            self.X_train, self.y_train, test_size=blend_ratio, random_state=self.random_state\n",
        "        )\n",
        "        \n",
        "        # Base modelleri blend train ile eÄŸit\n",
        "        blend_predictions = []\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X_blend_train, y_blend_train)\n",
        "            blend_pred = model.predict(X_blend_val)\n",
        "            blend_predictions.append(blend_pred)\n",
        "        \n",
        "        # Meta features oluÅŸtur\n",
        "        meta_features = np.column_stack(blend_predictions)\n",
        "        \n",
        "        # Meta model eÄŸit\n",
        "        meta_model = Ridge(alpha=1.0, random_state=self.random_state)\n",
        "        meta_model.fit(meta_features, y_blend_val)\n",
        "        \n",
        "        # TÃ¼m train seti ile base modelleri yeniden eÄŸit\n",
        "        for model in self.base_models.values():\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        # Validation ve test tahminleri\n",
        "        val_meta_features = np.column_stack([\n",
        "            model.predict(self.X_val) for model in self.base_models.values()\n",
        "        ])\n",
        "        test_meta_features = np.column_stack([\n",
        "            model.predict(self.X_test) for model in self.base_models.values()\n",
        "        ])\n",
        "        \n",
        "        val_pred = meta_model.predict(val_meta_features)\n",
        "        test_pred = meta_model.predict(test_meta_features)\n",
        "        \n",
        "        val_rmse = np.sqrt(mean_squared_error(self.y_val, val_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "        val_r2 = r2_score(self.y_val, val_pred)\n",
        "        test_r2 = r2_score(self.y_test, test_pred)\n",
        "        \n",
        "        self.ensemble_models['blending'] = {\n",
        "            'base_models': self.base_models,\n",
        "            'meta_model': meta_model\n",
        "        }\n",
        "        self.results['blending'] = {\n",
        "            'val_rmse': val_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'val_r2': val_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'blend_ratio': blend_ratio\n",
        "        }\n",
        "        \n",
        "        print(f\"âœ… Blending Ensemble:\")\n",
        "        print(f\"  â€¢ Validation RMSE: {val_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"  â€¢ Test RÂ²: {test_r2:.4f}\")\n",
        "        \n",
        "        return self.ensemble_models['blending']\n",
        "    \n",
        "    def compare_ensembles(self):\n",
        "        \"\"\"Ensemble yÃ¶ntemlerini karÅŸÄ±laÅŸtÄ±r\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ HenÃ¼z ensemble oluÅŸturulmamÄ±ÅŸ!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ğŸ† ENSEMBLE METHODS KARÅILAÅTIRMASI\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        # Base modellerin performansÄ±nÄ± da ekle\n",
        "        base_results = {}\n",
        "        for name, model in self.base_models.items():\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            test_pred = model.predict(self.X_test)\n",
        "            base_results[f'base_{name}'] = {\n",
        "                'val_rmse': np.sqrt(mean_squared_error(self.y_val, val_pred)),\n",
        "                'test_rmse': np.sqrt(mean_squared_error(self.y_test, test_pred)),\n",
        "                'val_r2': r2_score(self.y_val, val_pred),\n",
        "                'test_r2': r2_score(self.y_test, test_pred)\n",
        "            }\n",
        "        \n",
        "        # TÃ¼m sonuÃ§larÄ± birleÅŸtir\n",
        "        all_results = {**base_results, **self.results}\n",
        "        \n",
        "        comparison_df = pd.DataFrame({\n",
        "            method: {\n",
        "                'Val RMSE': data['val_rmse'],\n",
        "                'Test RMSE': data['test_rmse'],\n",
        "                'Val RÂ²': data['val_r2'],\n",
        "                'Test RÂ²': data['test_r2']\n",
        "            }\n",
        "            for method, data in all_results.items()\n",
        "        }).T\n",
        "        \n",
        "        comparison_df = comparison_df.sort_values('Test RMSE')\n",
        "        print(comparison_df.round(4))\n",
        "        \n",
        "        # En iyi ensemble'Ä± bul\n",
        "        ensemble_only = {k: v for k, v in self.results.items()}\n",
        "        best_ensemble = min(ensemble_only.keys(), key=lambda x: ensemble_only[x]['test_rmse'])\n",
        "        \n",
        "        print(f\"\\nğŸ† En iyi ensemble: {best_ensemble}\")\n",
        "        print(f\"ğŸ“Š Test RMSE: {ensemble_only[best_ensemble]['test_rmse']:.4f}\")\n",
        "        \n",
        "        return comparison_df, best_ensemble\n",
        "    \n",
        "    def plot_ensemble_comparison(self):\n",
        "        \"\"\"Ensemble sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"âŒ HenÃ¼z ensemble oluÅŸturulmamÄ±ÅŸ!\")\n",
        "            return\n",
        "        \n",
        "        # Base modellerin sonuÃ§larÄ±nÄ± da dahil et\n",
        "        all_models = {}\n",
        "        \n",
        "        # Base modeller\n",
        "        for name, model in self.base_models.items():\n",
        "            val_pred = model.predict(self.X_val)\n",
        "            test_pred = model.predict(self.X_test)\n",
        "            all_models[f'Base_{name.upper()}'] = {\n",
        "                'val_rmse': np.sqrt(mean_squared_error(self.y_val, val_pred)),\n",
        "                'test_rmse': np.sqrt(mean_squared_error(self.y_test, test_pred))\n",
        "            }\n",
        "        \n",
        "        # Ensemble modeller\n",
        "        for name, result in self.results.items():\n",
        "            all_models[f'Ensemble_{name.upper()}'] = {\n",
        "                'val_rmse': result['val_rmse'],\n",
        "                'test_rmse': result['test_rmse']\n",
        "            }\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # RMSE karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
        "        models = list(all_models.keys())\n",
        "        val_rmse = [all_models[model]['val_rmse'] for model in models]\n",
        "        test_rmse = [all_models[model]['test_rmse'] for model in models]\n",
        "        \n",
        "        x_pos = np.arange(len(models))\n",
        "        width = 0.35\n",
        "        \n",
        "        ax1.bar(x_pos - width/2, val_rmse, width, label='Validation RMSE', alpha=0.8)\n",
        "        ax1.bar(x_pos + width/2, test_rmse, width, label='Test RMSE', alpha=0.8)\n",
        "        ax1.set_xlabel('Models')\n",
        "        ax1.set_ylabel('RMSE')\n",
        "        ax1.set_title('ğŸ“Š Model Performance Comparison')\n",
        "        ax1.set_xticks(x_pos)\n",
        "        ax1.set_xticklabels(models, rotation=45, ha='right')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Ensemble improvement\n",
        "        base_best_rmse = min([all_models[m]['test_rmse'] for m in models if m.startswith('Base_')])\n",
        "        ensemble_models = [m for m in models if m.startswith('Ensemble_')]\n",
        "        improvements = [(base_best_rmse - all_models[m]['test_rmse']) / base_best_rmse * 100 \n",
        "                       for m in ensemble_models]\n",
        "        \n",
        "        colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "        ax2.bar(range(len(ensemble_models)), improvements, color=colors, alpha=0.7)\n",
        "        ax2.set_xlabel('Ensemble Methods')\n",
        "        ax2.set_ylabel('Improvement (%)')\n",
        "        ax2.set_title('ğŸš€ Ensemble Improvement vs Best Base Model')\n",
        "        ax2.set_xticks(range(len(ensemble_models)))\n",
        "        ax2.set_xticklabels([m.replace('Ensemble_', '') for m in ensemble_models], rotation=45, ha='right')\n",
        "        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"âœ… EnsembleTrainer sÄ±nÄ±fÄ± oluÅŸturuldu!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble eÄŸitimi yapalÄ±m\n",
        "ensemble_trainer = EnsembleTrainer(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "print(\"ğŸ¯ ENSEMBLE METHODS EÄÄ°TÄ°MÄ°\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Voting Ensemble\n",
        "voting_model = ensemble_trainer.create_voting_ensemble()\n",
        "\n",
        "# 2. Stacking Ensemble  \n",
        "stacking_model = ensemble_trainer.create_stacking_ensemble()\n",
        "\n",
        "# 3. Blending Ensemble\n",
        "blending_model = ensemble_trainer.create_blending_ensemble()\n",
        "\n",
        "# TÃ¼m ensemble yÃ¶ntemlerini karÅŸÄ±laÅŸtÄ±r\n",
        "ensemble_comparison, best_ensemble_method = ensemble_trainer.compare_ensembles()\n",
        "\n",
        "# GÃ¶rselleÅŸtirme\n",
        "ensemble_trainer.plot_ensemble_comparison()\n",
        "\n",
        "print(f\"\\nğŸ‰ En iyi ensemble method: {best_ensemble_method}\")\n",
        "print(f\"ğŸ“Š En iyi test RMSE: {ensemble_trainer.results[best_ensemble_method]['test_rmse']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Learning Curves ve Model Diagnostics\n",
        "\n",
        "Model performansÄ±nÄ± daha detaylÄ± analiz etmek iÃ§in learning curves ve Ã§eÅŸitli diagnostics kullanacaÄŸÄ±z:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_learning_curves(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
        "    \"\"\"Learning curves Ã§izimi\"\"\"\n",
        "    print(\"ğŸ“ˆ Learning curves hesaplanÄ±yor...\")\n",
        "    \n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X, y, cv=cv, train_sizes=train_sizes, \n",
        "        scoring='neg_mean_squared_error', n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # RMSE'ye Ã§evir\n",
        "    train_rmse = np.sqrt(-train_scores)\n",
        "    val_rmse = np.sqrt(-val_scores)\n",
        "    \n",
        "    # Ortalama ve standart sapma\n",
        "    train_rmse_mean = train_rmse.mean(axis=1)\n",
        "    train_rmse_std = train_rmse.std(axis=1)\n",
        "    val_rmse_mean = val_rmse.mean(axis=1)\n",
        "    val_rmse_std = val_rmse.std(axis=1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Learning curves\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(train_sizes, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
        "    plt.fill_between(train_sizes, train_rmse_mean - train_rmse_std, \n",
        "                     train_rmse_mean + train_rmse_std, alpha=0.2, color='blue')\n",
        "    \n",
        "    plt.plot(train_sizes, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
        "    plt.fill_between(train_sizes, val_rmse_mean - val_rmse_std, \n",
        "                     val_rmse_mean + val_rmse_std, alpha=0.2, color='red')\n",
        "    \n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('ğŸ“ˆ Learning Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Overfitting analizi\n",
        "    plt.subplot(2, 2, 2)\n",
        "    overfitting = val_rmse_mean - train_rmse_mean\n",
        "    plt.plot(train_sizes, overfitting, 'o-', color='orange')\n",
        "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('Validation RMSE - Training RMSE')\n",
        "    plt.title('âš ï¸ Overfitting Analysis')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Final performance\n",
        "    final_train_rmse = train_rmse_mean[-1]\n",
        "    final_val_rmse = val_rmse_mean[-1]\n",
        "    final_gap = final_val_rmse - final_train_rmse\n",
        "    \n",
        "    plt.subplot(2, 2, 3)\n",
        "    metrics = ['Training RMSE', 'Validation RMSE', 'Performance Gap']\n",
        "    values = [final_train_rmse, final_val_rmse, final_gap]\n",
        "    colors = ['blue', 'red', 'orange']\n",
        "    \n",
        "    bars = plt.bar(metrics, values, color=colors, alpha=0.7)\n",
        "    plt.title('ğŸ“Š Final Performance Metrics')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                f'{value:.4f}', ha='center', va='bottom')\n",
        "    \n",
        "    # Convergence analysis\n",
        "    plt.subplot(2, 2, 4)\n",
        "    val_improvement = np.diff(val_rmse_mean)\n",
        "    plt.plot(train_sizes[1:], val_improvement, 'o-', color='green')\n",
        "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('RMSE Improvement')\n",
        "    plt.title('ğŸ¯ Validation Performance Improvement')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"âœ… Learning curves analizi tamamlandÄ±!\")\n",
        "    print(f\"ğŸ“Š Final training RMSE: {final_train_rmse:.4f}\")\n",
        "    print(f\"ğŸ“Š Final validation RMSE: {final_val_rmse:.4f}\")\n",
        "    print(f\"âš ï¸ Performance gap: {final_gap:.4f}\")\n",
        "    \n",
        "    return train_sizes, train_rmse_mean, val_rmse_mean\n",
        "\n",
        "def plot_validation_curves(model, X, y, param_name, param_range, cv=5):\n",
        "    \"\"\"Validation curves Ã§izimi\"\"\"\n",
        "    print(f\"ğŸ“Š Validation curves hesaplanÄ±yor ({param_name})...\")\n",
        "    \n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model, X, y, param_name=param_name, param_range=param_range,\n",
        "        cv=cv, scoring='neg_mean_squared_error', n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # RMSE'ye Ã§evir\n",
        "    train_rmse = np.sqrt(-train_scores)\n",
        "    val_rmse = np.sqrt(-val_scores)\n",
        "    \n",
        "    # Ortalama ve standart sapma\n",
        "    train_rmse_mean = train_rmse.mean(axis=1)\n",
        "    train_rmse_std = train_rmse.std(axis=1)\n",
        "    val_rmse_mean = val_rmse.mean(axis=1)\n",
        "    val_rmse_std = val_rmse.std(axis=1)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    plt.plot(param_range, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
        "    plt.fill_between(param_range, train_rmse_mean - train_rmse_std, \n",
        "                     train_rmse_mean + train_rmse_std, alpha=0.2, color='blue')\n",
        "    \n",
        "    plt.plot(param_range, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
        "    plt.fill_between(param_range, val_rmse_mean - val_rmse_std, \n",
        "                     val_rmse_mean + val_rmse_std, alpha=0.2, color='red')\n",
        "    \n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title(f'ğŸ“Š Validation Curve for {param_name}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # En iyi parametreyi bul\n",
        "    best_idx = np.argmin(val_rmse_mean)\n",
        "    best_param = param_range[best_idx]\n",
        "    best_score = val_rmse_mean[best_idx]\n",
        "    \n",
        "    plt.axvline(x=best_param, color='green', linestyle='--', alpha=0.7, \n",
        "                label=f'Best: {best_param} (RMSE: {best_score:.4f})')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"âœ… En iyi {param_name}: {best_param}\")\n",
        "    print(f\"ğŸ“Š En iyi validation RMSE: {best_score:.4f}\")\n",
        "    \n",
        "    return best_param, best_score\n",
        "\n",
        "# En iyi model ile learning curves analizi\n",
        "print(\"ğŸ” MODEL DIAGNOSTICS VE LEARNING CURVES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Learning curves\n",
        "train_sizes, train_rmse, val_rmse = plot_learning_curves(\n",
        "    best_model, X_train, y_train, cv=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation curves - n_estimators parametresi iÃ§in\n",
        "print(\"\\nğŸ“Š VALIDATION CURVES ANALÄ°ZÄ°\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Random Forest iÃ§in n_estimators validation curve\n",
        "n_estimators_range = [50, 100, 150, 200, 250, 300, 400, 500]\n",
        "best_n_estimators, best_score = plot_validation_curves(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    X_train, y_train,\n",
        "    'n_estimators',\n",
        "    n_estimators_range,\n",
        "    cv=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Model Versioning ve Experiment Tracking\n",
        "\n",
        "MLflow ile model versioning ve experiment tracking yapacaÄŸÄ±z:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelTracker:\n",
        "    \"\"\"Model versioning ve tracking iÃ§in sÄ±nÄ±f\"\"\"\n",
        "    \n",
        "    def __init__(self, experiment_name=\"Advanced_Model_Training\"):\n",
        "        self.experiment_name = experiment_name\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        self.model_registry = {}\n",
        "    \n",
        "    def log_model_experiment(self, model, model_name, X_train, y_train, X_val, y_val, \n",
        "                           X_test, y_test, hyperparams=None, model_type=\"single\"):\n",
        "        \"\"\"Model experiment'ini kaydet\"\"\"\n",
        "        \n",
        "        with mlflow.start_run(run_name=f\"{model_name}_{model_type}\"):\n",
        "            # Model eÄŸitimi\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Tahminler\n",
        "            train_pred = model.predict(X_train)\n",
        "            val_pred = model.predict(X_val)\n",
        "            test_pred = model.predict(X_test)\n",
        "            \n",
        "            # Metrikler\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "            \n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "            \n",
        "            # MLflow'a log\n",
        "            mlflow.log_param(\"model_name\", model_name)\n",
        "            mlflow.log_param(\"model_type\", model_type)\n",
        "            mlflow.log_param(\"training_samples\", len(X_train))\n",
        "            \n",
        "            if hyperparams:\n",
        "                mlflow.log_params(hyperparams)\n",
        "            \n",
        "            mlflow.log_metric(\"train_rmse\", train_rmse)\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            mlflow.log_metric(\"test_rmse\", test_rmse)\n",
        "            mlflow.log_metric(\"train_r2\", train_r2)\n",
        "            mlflow.log_metric(\"val_r2\", val_r2)\n",
        "            mlflow.log_metric(\"test_r2\", test_r2)\n",
        "            mlflow.log_metric(\"training_time\", training_time)\n",
        "            mlflow.log_metric(\"overfitting_score\", train_rmse - val_rmse)\n",
        "            \n",
        "            # Model'i kaydet\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "            \n",
        "            # Model registry'e ekle\n",
        "            run_id = mlflow.active_run().info.run_id\n",
        "            self.model_registry[model_name] = {\n",
        "                'run_id': run_id,\n",
        "                'model': model,\n",
        "                'metrics': {\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'val_rmse': val_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'test_r2': test_r2\n",
        "                },\n",
        "                'training_time': training_time,\n",
        "                'timestamp': datetime.now()\n",
        "            }\n",
        "            \n",
        "            print(f\"âœ… {model_name} logged to MLflow (Run ID: {run_id})\")\n",
        "            print(f\"   ğŸ“Š Test RMSE: {test_rmse:.4f}, Test RÂ²: {test_r2:.4f}\")\n",
        "            \n",
        "            return run_id\n",
        "    \n",
        "    def register_best_model(self, model_name=\"BestModel\"):\n",
        "        \"\"\"En iyi modeli registry'e kaydet\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"âŒ KayÄ±tlÄ± model yok!\")\n",
        "            return\n",
        "        \n",
        "        # En iyi modeli bul\n",
        "        best_model_name = min(self.model_registry.keys(), \n",
        "                             key=lambda x: self.model_registry[x]['metrics']['test_rmse'])\n",
        "        \n",
        "        best_model_info = self.model_registry[best_model_name]\n",
        "        \n",
        "        # Model registry'e kaydet\n",
        "        model_uri = f\"runs:/{best_model_info['run_id']}/model\"\n",
        "        \n",
        "        try:\n",
        "            mlflow.register_model(\n",
        "                model_uri=model_uri,\n",
        "                name=model_name\n",
        "            )\n",
        "            print(f\"ğŸ† En iyi model '{model_name}' olarak registry'e kaydedildi!\")\n",
        "            print(f\"ğŸ“Š Model: {best_model_name}\")\n",
        "            print(f\"ğŸ“Š Test RMSE: {best_model_info['metrics']['test_rmse']:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Model registry'e kaydedilemedi: {e}\")\n",
        "        \n",
        "        return best_model_name, best_model_info\n",
        "    \n",
        "    def compare_all_models(self):\n",
        "        \"\"\"TÃ¼m kayÄ±tlÄ± modelleri karÅŸÄ±laÅŸtÄ±r\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"âŒ KayÄ±tlÄ± model yok!\")\n",
        "            return\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ğŸ“Š TÃœM MODEL KARÅILAÅTIRMASI\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        comparison_data = []\n",
        "        for name, info in self.model_registry.items():\n",
        "            comparison_data.append({\n",
        "                'Model': name,\n",
        "                'Test RMSE': info['metrics']['test_rmse'],\n",
        "                'Test RÂ²': info['metrics']['test_r2'],\n",
        "                'Val RMSE': info['metrics']['val_rmse'],\n",
        "                'Training Time (s)': info['training_time'],\n",
        "                'Timestamp': info['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "        \n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.sort_values('Test RMSE')\n",
        "        print(comparison_df.to_string(index=False))\n",
        "        \n",
        "        return comparison_df\n",
        "    \n",
        "    def plot_model_comparison(self):\n",
        "        \"\"\"Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi\"\"\"\n",
        "        if not self.model_registry:\n",
        "            print(\"âŒ KayÄ±tlÄ± model yok!\")\n",
        "            return\n",
        "        \n",
        "        models = list(self.model_registry.keys())\n",
        "        test_rmse = [self.model_registry[m]['metrics']['test_rmse'] for m in models]\n",
        "        test_r2 = [self.model_registry[m]['metrics']['test_r2'] for m in models]\n",
        "        training_times = [self.model_registry[m]['training_time'] for m in models]\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Test RMSE comparison\n",
        "        axes[0, 0].barh(models, test_rmse, alpha=0.7)\n",
        "        axes[0, 0].set_xlabel('Test RMSE')\n",
        "        axes[0, 0].set_title('ğŸ¯ Test RMSE Comparison')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Test RÂ² comparison\n",
        "        axes[0, 1].barh(models, test_r2, alpha=0.7, color='green')\n",
        "        axes[0, 1].set_xlabel('Test RÂ²')\n",
        "        axes[0, 1].set_title('ğŸ“Š Test RÂ² Comparison')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Training time comparison\n",
        "        axes[1, 0].barh(models, training_times, alpha=0.7, color='orange')\n",
        "        axes[1, 0].set_xlabel('Training Time (seconds)')\n",
        "        axes[1, 0].set_title('â±ï¸ Training Time Comparison')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Performance vs Time scatter\n",
        "        axes[1, 1].scatter(training_times, test_rmse, s=100, alpha=0.7, c=test_r2, cmap='viridis')\n",
        "        for i, model in enumerate(models):\n",
        "            axes[1, 1].annotate(model, (training_times[i], test_rmse[i]), \n",
        "                               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "        axes[1, 1].set_xlabel('Training Time (seconds)')\n",
        "        axes[1, 1].set_ylabel('Test RMSE')\n",
        "        axes[1, 1].set_title('ğŸš€ Performance vs Training Time')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Model tracker'Ä± baÅŸlat\n",
        "tracker = ModelTracker(\"Advanced_Model_Training_Final\")\n",
        "\n",
        "print(\"ğŸ“ MODEL TRACKING VE VERSIONING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# En iyi hyperparameter optimization modelini kaydet\n",
        "if 'best_model' in locals():\n",
        "    tracker.log_model_experiment(\n",
        "        best_model, \n",
        "        f\"Optimized_{best_optimization_method}\",\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "        hyperparams=optimizer.results[best_optimization_method]['best_params'],\n",
        "        model_type=\"optimized\"\n",
        "    )\n",
        "\n",
        "# En iyi ensemble modelini kaydet\n",
        "if 'ensemble_trainer' in locals():\n",
        "    best_ensemble_model = ensemble_trainer.ensemble_models[best_ensemble_method]\n",
        "    if best_ensemble_method == 'blending':\n",
        "        # Blending iÃ§in Ã¶zel iÅŸlem gerekli\n",
        "        print(f\"âš ï¸ Blending model complex structure - logging metadata only\")\n",
        "    else:\n",
        "        tracker.log_model_experiment(\n",
        "            best_ensemble_model,\n",
        "            f\"Ensemble_{best_ensemble_method}\",\n",
        "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "            model_type=\"ensemble\"\n",
        "        )\n",
        "\n",
        "# Baseline modelleri kaydet\n",
        "baseline_models = {\n",
        "    'RandomForest_Baseline': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting_Baseline': GradientBoostingRegressor(random_state=42),\n",
        "    'Ridge_Baseline': Ridge(alpha=1.0, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in baseline_models.items():\n",
        "    tracker.log_model_experiment(\n",
        "        model, name, X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "        model_type=\"baseline\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ¼m modelleri karÅŸÄ±laÅŸtÄ±r\n",
        "final_comparison = tracker.compare_all_models()\n",
        "\n",
        "# En iyi modeli registry'e kaydet\n",
        "best_model_name, best_model_info = tracker.register_best_model(\"California_Housing_Best_Model\")\n",
        "\n",
        "# GÃ¶rselleÅŸtirme\n",
        "tracker.plot_model_comparison()\n",
        "\n",
        "print(f\"\\nğŸ‰ Model training sÃ¼reci tamamlandÄ±!\")\n",
        "print(f\"ğŸ† En iyi model: {best_model_name}\")\n",
        "print(f\"ğŸ“Š Final test RMSE: {best_model_info['metrics']['test_rmse']:.4f}\")\n",
        "print(f\"ğŸ“Š Final test RÂ²: {best_model_info['metrics']['test_r2']:.4f}\")\n",
        "print(f\"â±ï¸ Training time: {best_model_info['training_time']:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Ã–zet ve SonuÃ§lar\n",
        "\n",
        "### ğŸ¯ Bu BÃ¶lÃ¼mde Neler Ã–ÄŸrendik?\n",
        "\n",
        "1. **Advanced Cross-Validation**: FarklÄ± CV stratejilerini karÅŸÄ±laÅŸtÄ±rdÄ±k\n",
        "2. **Hyperparameter Optimization**: Grid Search, Random Search ve Bayesian Optimization\n",
        "3. **Ensemble Methods**: Voting, Stacking ve Blending teknikleri\n",
        "4. **Model Diagnostics**: Learning curves ve validation curves\n",
        "5. **Model Tracking**: MLflow ile experiment tracking ve versioning\n",
        "\n",
        "### ğŸ“Š Ana Bulgular:\n",
        "\n",
        "- **En Ä°yi Optimization YÃ¶ntemi**: Bayesian optimization genellikle en etkili\n",
        "- **Ensemble AvantajÄ±**: Tek modellere gÃ¶re %5-15 performans artÄ±ÅŸÄ±\n",
        "- **Training Efficiency**: Random search, grid search'ten Ã§ok daha hÄ±zlÄ±\n",
        "- **Model Stability**: Cross-validation ile daha gÃ¼venilir sonuÃ§lar\n",
        "\n",
        "### ğŸš€ Sonraki AdÄ±mlar:\n",
        "\n",
        "1. **Model Deployment**: En iyi modeli production ortamÄ±na alma\n",
        "2. **Monitoring**: Model performansÄ±nÄ± sÃ¼rekli izleme\n",
        "3. **A/B Testing**: FarklÄ± model versiyonlarÄ±nÄ± test etme\n",
        "4. **Automation**: Pipeline'larÄ±n otomasyonu\n",
        "\n",
        "### ğŸ’¡ Ä°puÃ§larÄ±:\n",
        "\n",
        "- Her zaman baseline modeller ile karÅŸÄ±laÅŸtÄ±rÄ±n\n",
        "- Overfitting iÃ§in learning curves'u kontrol edin\n",
        "- Ensemble yÃ¶ntemleri denemeyi unutmayÄ±n\n",
        "- Experiment tracking kullanarak sonuÃ§larÄ± kaydedin\n",
        "- Cross-validation stratejisini data tipine gÃ¶re seÃ§in\n",
        "\n",
        "---\n",
        "\n",
        "**Level 4 TamamlandÄ±! ğŸ‰**\n",
        "\n",
        "ArtÄ±k advanced model training tekniklerini kullanarak yÃ¼ksek performanslÄ± modeller geliÅŸtirebilirsiniz!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
