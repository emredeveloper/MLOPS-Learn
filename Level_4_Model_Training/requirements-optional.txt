# Optional distributed training and deep learning runtimes
ray[train]>=2.9.0
dask[distributed]>=2023.12.1
horovod>=0.28,<0.29
pytorch-lightning>=2.1,<2.2
torch>=2.1,<2.2
tensorflow>=2.14,<2.15
transformers>=4.36,<4.37
sacred>=0.8,<0.9
comet-ml>=3.37,<3.38
