# MLOps Temel Kavramlar SÃ¶zlÃ¼ÄŸÃ¼

Bu dosya Level 1: MLOps GiriÅŸ notebook'unda geÃ§en tÃ¼m kavramlarÄ± detaylÄ± olarak aÃ§Ä±klamaktadÄ±r.

## ğŸ“š Ä°Ã§indekiler
- [MLOps ve Temel Kavramlar](#mlops-ve-temel-kavramlar)
- [AraÃ§lar ve Teknolojiler](#araÃ§lar-ve-teknolojiler)
- [Model Lifecycle](#model-lifecycle)
- [Metrikler ve DeÄŸerlendirme](#metrikler-ve-deÄŸerlendirme)

---

## MLOps ve Temel Kavramlar

### ğŸ¤– MLOps (Machine Learning Operations)
**TanÄ±m:** Makine Ã¶ÄŸrenmesi modellerinin geliÅŸtirme, daÄŸÄ±tÄ±m ve bakÄ±mÄ±nÄ± otomatikleÅŸtiren DevOps prensiplerine dayalÄ± bir metodoloji.

**Ana BileÅŸenleri:**
- **Development (GeliÅŸtirme):** Model tasarÄ±mÄ±, feature engineering, algoritma seÃ§imi
- **Operations (Operasyonlar):** Model daÄŸÄ±tÄ±mÄ±, monitoring, maintenance
- **Infrastructure (AltyapÄ±):** Ã–lÃ§eklenebilir hesaplama kaynaklarÄ±, data storage

### ğŸ”„ CI/CD Pipeline
**TanÄ±m:** Continuous Integration/Continuous Deployment - Kod deÄŸiÅŸikliklerinin otomatik olarak test edilip production'a deploy edilmesi sÃ¼reci.

**MLOps'taki RolÃ¼:**
- Kod deÄŸiÅŸikliklerinin otomatik testi
- Model eÄŸitiminin otomatikleÅŸtirilmesi
- Model deployment sÃ¼recinin otomatikleÅŸtirilmesi

### ğŸ“Š Experiment Tracking
**TanÄ±m:** ML deneylerin sistematik olarak kaydedilmesi ve takip edilmesi sÃ¼reci.

**Kaydedilecek Bilgiler:**
- Model parametreleri (hyperparameters)
- EÄŸitim metrikleri (accuracy, loss, etc.)
- Model artifacts (eÄŸitilmiÅŸ model dosyalarÄ±)
- Veri versiyonlarÄ±
- Kod versiyonlarÄ±

### ğŸ”§ Versiyonlama
**Model Versiyonlama:** Her model iterasyonunun unique identifier ile kaydedilmesi
**Veri Versiyonlama:** Veri setlerinin deÄŸiÅŸikliklerinin takip edilmesi
**Kod Versiyonlama:** Git benzeri araÃ§larla kod deÄŸiÅŸikliklerinin takibi

---

## AraÃ§lar ve Teknolojiler

### ğŸ“ˆ MLflow
**TanÄ±m:** AÃ§Ä±k kaynak ML lifecycle yÃ¶netim platformu.

**Ana FonksiyonlarÄ±:**
- **MLflow Tracking:** Experiment logging ve comparison
- **MLflow Projects:** Reproducible ML code packaging
- **MLflow Models:** Model packaging ve deployment
- **MLflow Registry:** Centralized model store

**Temel KullanÄ±m:**
```python
import mlflow
import mlflow.sklearn

# Experiment baÅŸlat
mlflow.set_experiment("my-experiment")

with mlflow.start_run():
    # Parametreleri kaydet
    mlflow.log_param("n_estimators", 100)
    
    # Metrikleri kaydet
    mlflow.log_metric("accuracy", 0.95)
    
    # Model kaydet
    mlflow.sklearn.log_model(model, "model")
```

### ğŸ—ƒï¸ DVC (Data Version Control)
**TanÄ±m:** Veri setleri ve ML modelleri iÃ§in Git-benzeri version control sistemi.

**Temel KomutlarÄ±:**
- `dvc init`: Repository'yi DVC iÃ§in initialize et
- `dvc add data.csv`: Veri dosyasÄ±nÄ± DVC tracking'e ekle
- `dvc push`: Verileri remote storage'a yÃ¼kle
- `dvc pull`: Verileri remote'dan indir

### ğŸ³ Docker
**TanÄ±m:** UygulamalarÄ± containerize etmek iÃ§in kullanÄ±lan platform.

**MLOps'taki FaydalarÄ±:**
- Environment consistency
- Reproducibility
- Easy deployment
- Scalability

### â˜¸ï¸ Kubernetes
**TanÄ±m:** Container orchestration platformu.

**MLOps Use Cases:**
- Model serving at scale
- Resource management
- Load balancing
- Auto-scaling

### ğŸ“Š Apache Airflow
**TanÄ±m:** Workflow orchestration ve scheduling platformu.

**MLOps'taki KullanÄ±mÄ±:**
- Data pipeline orchestration
- Model training workflows
- Automated retraining
- ETL processes

---

## Model Lifecycle

### ğŸ¯ Model Development
**AÅŸamalarÄ±:**
1. **Problem Definition:** Business problem'Ä±n ML problem'Ä±na Ã§evrilmesi
2. **Data Collection:** Gerekli verilerin toplanmasÄ±
3. **Exploratory Data Analysis (EDA):** Verinin anlaÅŸÄ±lmasÄ±
4. **Feature Engineering:** Ã–zellik Ã§Ä±karÄ±mÄ± ve dÃ¶nÃ¼ÅŸtÃ¼rme
5. **Model Selection:** Uygun algoritmanÄ±n seÃ§ilmesi
6. **Model Training:** Modelin eÄŸitilmesi
7. **Model Evaluation:** Performans deÄŸerlendirmesi

### ğŸš€ Model Deployment
**Deployment Stratejileri:**
- **Blue-Green Deployment:** Ä°ki paralel environment kullanma
- **Canary Deployment:** Kademeli olarak traffic'i yeni modele yÃ¶nlendirme
- **A/B Testing:** Ä°ki model versiyonunu karÅŸÄ±laÅŸtÄ±rma

### ğŸ“Š Model Monitoring
**Ä°zlenecek Metrikler:**
- **Performance Metrics:** Accuracy, precision, recall
- **Business Metrics:** Revenue impact, user engagement
- **Technical Metrics:** Latency, throughput, error rates
- **Data Quality:** Input data drift, schema changes

### ğŸ”„ Model Retraining
**Retraining Triggers:**
- Performance degradation
- Data drift detection
- Scheduled retraining
- Business rule changes

---

## Metrikler ve DeÄŸerlendirme

### ğŸ“Š Classification Metrics

#### Accuracy (DoÄŸruluk)
**FormÃ¼l:** `(TP + TN) / (TP + TN + FP + FN)`
**AÃ§Ä±klama:** DoÄŸru tahminlerin toplam tahminlere oranÄ±

#### Precision (Kesinlik)
**FormÃ¼l:** `TP / (TP + FP)`
**AÃ§Ä±klama:** Pozitif tahmin edilenlerin ne kadarÄ±nÄ±n gerÃ§ekten pozitif olduÄŸu

#### Recall (DuyarlÄ±lÄ±k)
**FormÃ¼l:** `TP / (TP + FN)`
**AÃ§Ä±klama:** GerÃ§ek pozitiflerin ne kadarÄ±nÄ±n doÄŸru tahmin edildiÄŸi

#### F1-Score
**FormÃ¼l:** `2 * (Precision * Recall) / (Precision + Recall)`
**AÃ§Ä±klama:** Precision ve Recall'Ä±n harmonik ortalamasÄ±

### ğŸ“ˆ Regression Metrics

#### MSE (Mean Squared Error)
**FormÃ¼l:** `Î£(y_true - y_pred)Â² / n`
**AÃ§Ä±klama:** HatalarÄ±n karelerinin ortalamasÄ±

#### RMSE (Root Mean Squared Error)
**FormÃ¼l:** `âˆš(MSE)`
**AÃ§Ä±klama:** MSE'nin karekÃ¶kÃ¼, orijinal birim cinsinden hata

#### MAE (Mean Absolute Error)
**FormÃ¼l:** `Î£|y_true - y_pred| / n`
**AÃ§Ä±klama:** Mutlak hatalarÄ±n ortalamasÄ±

#### RÂ² (R-squared)
**FormÃ¼l:** `1 - (SS_res / SS_tot)`
**AÃ§Ä±klama:** Modelin aÃ§Ä±kladÄ±ÄŸÄ± varyansÄ±n oranÄ±

---

## ğŸ”§ Teknik Kavramlar

### ğŸ›ï¸ Hyperparameters
**TanÄ±m:** Model eÄŸitimi Ã¶ncesinde belirlenen ve eÄŸitim sÃ¼reci boyunca sabit kalan parametreler.

**Ã–rnekler:**
- Learning rate
- Number of epochs
- Batch size
- Number of hidden layers
- Regularization parameters

### ğŸ¯ Cross-Validation
**TanÄ±m:** Model performansÄ±nÄ± gÃ¼venilir ÅŸekilde deÄŸerlendirmek iÃ§in veri setini farklÄ± ÅŸekillerde bÃ¶lerek model eÄŸitimi ve testi yapma tekniÄŸi.

**TÃ¼rleri:**
- **K-Fold CV:** Veriyi K parÃ§aya bÃ¶lme
- **Stratified CV:** SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koruyarak bÃ¶lme
- **Time Series CV:** Zaman serisi verileri iÃ§in Ã¶zel bÃ¶lme

### ğŸ“Š Train-Validation-Test Split
**Train Set:** Modelin Ã¶ÄŸrendiÄŸi veri seti (%70-80)
**Validation Set:** Hyperparameter tuning iÃ§in kullanÄ±lan set (%10-15)
**Test Set:** Final model performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan set (%10-15)

### ğŸ­ Overfitting vs Underfitting
**Overfitting:** Modelin training data'ya aÅŸÄ±rÄ± uyum saÄŸlamasÄ±, generalization yeteneÄŸini kaybetmesi
**Underfitting:** Modelin yeterince complex olmamasÄ±, pattern'leri yakalayamamasÄ±

---

## ğŸ› ï¸ Praktik Uygulamalar

### ğŸ“ Experiment Logging
```python
# Temel MLflow logging
mlflow.log_param("parameter_name", value)
mlflow.log_metric("metric_name", value)
mlflow.log_artifact("file_path")
```

### ğŸ” Model Comparison
```python
# Birden fazla model karÅŸÄ±laÅŸtÄ±rmasÄ±
models = {
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "Logistic Regression": LogisticRegression()
}

for name, model in models.items():
    with mlflow.start_run(run_name=name):
        model.fit(X_train, y_train)
        accuracy = model.score(X_test, y_test)
        mlflow.log_metric("accuracy", accuracy)
```

### ğŸ“Š Performance Visualization
```python
# Classification report
from sklearn.metrics import classification_report
report = classification_report(y_test, y_pred)
print(report)

# Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
```

---

## ğŸ“ Best Practices

### âœ… Experiment Organization
1. **Clear Naming:** Experiment ve run'lar iÃ§in aÃ§Ä±klayÄ±cÄ± isimler kullan
2. **Consistent Logging:** Her experiment'te aynÄ± metrikleri logla
3. **Documentation:** Her experiment iÃ§in aÃ§Ä±klama ekle
4. **Reproducibility:** Random seed'leri kaydet

### ğŸ”„ Version Control
1. **Code Versioning:** Her experiment iÃ§in kod durumunu kaydet
2. **Data Versioning:** KullanÄ±lan veri setinin versiyonunu belirt
3. **Model Versioning:** Model artifacts'Ä±nÄ± version'la
4. **Environment Versioning:** Dependency'leri kaydet

### ğŸ“Š Monitoring
1. **Regular Checks:** Model performansÄ±nÄ± dÃ¼zenli kontrol et
2. **Alerting:** Performans dÃ¼ÅŸÃ¼ÅŸleri iÃ§in alarm kur
3. **Logging:** TÃ¼m Ã¶nemli event'leri logla
4. **Dashboards:** GÃ¶rsel monitoring dashboard'larÄ± oluÅŸtur

---

## ğŸ”— Ä°lgili Kaynaklar

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [DVC Documentation](https://dvc.org/doc)
- [MLOps Community](https://mlops.community/)
- [Google Cloud MLOps Guide](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
- [Azure MLOps](https://azure.microsoft.com/en-us/services/machine-learning/mlops/)
- [AWS MLOps](https://aws.amazon.com/machine-learning/mlops/)

---