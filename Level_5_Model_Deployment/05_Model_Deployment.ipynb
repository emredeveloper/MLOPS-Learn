{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 📦 Level 5: Model Deployment - Production'a Geçiş\n",
        "\n",
        "## 🎯 Bu Bölümde Neler Öğreneceğiz?\n",
        "\n",
        "1. **Model Packaging**: Modelleri production için hazırlama\n",
        "2. **REST API Development**: Flask/FastAPI ile model servisi\n",
        "3. **Docker Containerization**: Modelleri containerize etme\n",
        "4. **Cloud Deployment**: AWS/Azure/GCP'ye deploy etme\n",
        "5. **Load Testing**: Model performansını test etme\n",
        "6. **CI/CD Pipeline**: Otomatik deployment süreçleri\n",
        "\n",
        "### 🏗️ Production Deployment Architecture\n",
        "\n",
        "```\n",
        "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
        "│   Data Input    │───▶│  Model Service  │───▶│   Predictions   │\n",
        "│   (REST API)    │    │   (Container)   │    │   (JSON/DB)     │\n",
        "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
        "         │                       │                       │\n",
        "         ▼                       ▼                       ▼\n",
        "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
        "│   Monitoring    │    │   Load Balancer │    │     Logging     │\n",
        "│   (Metrics)     │    │   (Auto-scale)  │    │   (Analytics)   │\n",
        "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 Tüm kütüphaneler başarıyla yüklendi!\n",
            "🚀 Model Deployment eğitimine hazırız!\n",
            "📅 Başlangıç zamanı: 2025-07-02 17:21:39\n"
          ]
        }
      ],
      "source": [
        "# 📦 Gerekli kütüphaneleri yükleyelim\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import joblib\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Web framework\n",
        "from flask import Flask, request, jsonify\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import threading\n",
        "\n",
        "# Testing ve monitoring\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import psutil\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Plotting ayarları\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"📦 Tüm kütüphaneler başarıyla yüklendi!\")\n",
        "print(\"🚀 Model Deployment eğitimine hazırız!\")\n",
        "print(f\"📅 Başlangıç zamanı: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 Düzeltilmiş Model Packaging Kodu\n",
        "class ModelPackager:\n",
        "    \"\"\"Model packaging ve versioning için sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, model_dir=\"models\"):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.model_dir.mkdir(exist_ok=True)\n",
        "        self.metadata = {}\n",
        "    \n",
        "    def prepare_model(self):\n",
        "        \"\"\"Demo için basit bir model hazırla\"\"\"\n",
        "        print(\"🏠 California Housing veri seti ile model eğitiliyor...\")\n",
        "        \n",
        "        # Veri yükleme\n",
        "        california_housing = fetch_california_housing()\n",
        "        X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "        y = california_housing.target\n",
        "        \n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        \n",
        "        # Preprocessing\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        \n",
        "        # Model eğitimi\n",
        "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Test performansı\n",
        "        y_pred = self.model.predict(X_test_scaled)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        test_r2 = r2_score(y_test, y_pred)\n",
        "        \n",
        "        # Metadata (düzeltilmiş - .tolist() hatası giderildi)\n",
        "        self.metadata = {\n",
        "            'model_type': 'RandomForestRegressor',\n",
        "            'version': '1.0.0',\n",
        "            'training_date': datetime.now().isoformat(),\n",
        "            'test_rmse': test_rmse,\n",
        "            'test_r2': test_r2,\n",
        "            'feature_names': list(california_housing.feature_names),  # Düzeltme burada\n",
        "            'input_shape': X.shape[1],\n",
        "            'target_name': 'house_value'\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Model eğitildi!\")\n",
        "        print(f\"📊 Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"📊 Test R²: {test_r2:.4f}\")\n",
        "        \n",
        "        return X_test, y_test\n",
        "    \n",
        "    def save_model(self, version=\"v1\"):\n",
        "        \"\"\"Modeli ve preprocessing pipeline'ını kaydet\"\"\"\n",
        "        version_dir = self.model_dir / version\n",
        "        version_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        # Model kaydet\n",
        "        model_path = version_dir / \"model.pkl\"\n",
        "        joblib.dump(self.model, model_path)\n",
        "        \n",
        "        # Scaler kaydet\n",
        "        scaler_path = version_dir / \"scaler.pkl\"\n",
        "        joblib.dump(self.scaler, scaler_path)\n",
        "        \n",
        "        # Metadata kaydet\n",
        "        metadata_path = version_dir / \"metadata.json\"\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(self.metadata, f, indent=2)\n",
        "        \n",
        "        print(f\"💾 Model kaydedildi: {version_dir}\")\n",
        "        print(f\"   📁 Model: {model_path}\")\n",
        "        print(f\"   📁 Scaler: {scaler_path}\")\n",
        "        print(f\"   📁 Metadata: {metadata_path}\")\n",
        "        \n",
        "        return version_dir\n",
        "    \n",
        "    def load_model(self, version=\"v1\"):\n",
        "        \"\"\"Kaydedilmiş modeli yükle\"\"\"\n",
        "        version_dir = self.model_dir / version\n",
        "        \n",
        "        if not version_dir.exists():\n",
        "            raise FileNotFoundError(f\"Model version {version} bulunamadı!\")\n",
        "        \n",
        "        # Model yükle\n",
        "        model_path = version_dir / \"model.pkl\"\n",
        "        self.model = joblib.load(model_path)\n",
        "        \n",
        "        # Scaler yükle\n",
        "        scaler_path = version_dir / \"scaler.pkl\"\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "        \n",
        "        # Metadata yükle\n",
        "        metadata_path = version_dir / \"metadata.json\"\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            self.metadata = json.load(f)\n",
        "        \n",
        "        print(f\"📥 Model yüklendi: {version}\")\n",
        "        print(f\"📊 Model Type: {self.metadata['model_type']}\")\n",
        "        print(f\"📊 Version: {self.metadata['version']}\")\n",
        "        print(f\"📊 Test R²: {self.metadata['test_r2']:.4f}\")\n",
        "        \n",
        "        return self.model, self.scaler, self.metadata\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Tahmin yap\"\"\"\n",
        "        if hasattr(X, 'values'):\n",
        "            X = X.values\n",
        "        \n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "# Model paketi oluştur (düzeltilmiş sürüm)\n",
        "packager = ModelPackager()\n",
        "X_test, y_test = packager.prepare_model()\n",
        "model_version_dir = packager.save_model(\"v1\")\n",
        "\n",
        "print(\"\\n✅ Model packaging tamamlandı!\")\n",
        "print(f\"📁 Model dizini: {model_version_dir}\")\n",
        "print(f\"📊 Feature adları: {packager.metadata['feature_names']}\")\n",
        "print(f\"📊 Input shape: {packager.metadata['input_shape']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Model Hazırlama ve Packaging\n",
        "\n",
        "İlk olarak Level 4'ten en iyi modeli alıp deployment için hazırlayacağız:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏠 California Housing veri seti ile model eğitiliyor...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'tolist'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 119\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Model paketi oluştur\u001b[39;00m\n\u001b[32m    118\u001b[39m packager = ModelPackager()\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m X_test, y_test = \u001b[43mpackager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m model_version_dir = packager.save_model(\u001b[33m\"\u001b[39m\u001b[33mv1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Model packaging tamamlandı!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mModelPackager.prepare_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     35\u001b[39m test_r2 = r2_score(y_test, y_pred)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Metadata\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.metadata = {\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mRandomForestRegressor\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m1.0.0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraining_date\u001b[39m\u001b[33m'\u001b[39m: datetime.now().isoformat(),\n\u001b[32m     42\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtest_rmse\u001b[39m\u001b[33m'\u001b[39m: test_rmse,\n\u001b[32m     43\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtest_r2\u001b[39m\u001b[33m'\u001b[39m: test_r2,\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_names\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mcalifornia_housing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m(),\n\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m'\u001b[39m: X.shape[\u001b[32m1\u001b[39m],\n\u001b[32m     46\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtarget_name\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhouse_value\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     47\u001b[39m }\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Model eğitildi!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📊 Test RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'tolist'"
          ]
        }
      ],
      "source": [
        "class ModelPackager:\n",
        "    \"\"\"Model packaging ve versioning için sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, model_dir=\"models\"):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.model_dir.mkdir(exist_ok=True)\n",
        "        self.metadata = {}\n",
        "    \n",
        "    def prepare_model(self):\n",
        "        \"\"\"Demo için basit bir model hazırla\"\"\"\n",
        "        print(\"🏠 California Housing veri seti ile model eğitiliyor...\")\n",
        "        \n",
        "        # Veri yükleme\n",
        "        california_housing = fetch_california_housing()\n",
        "        X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "        y = california_housing.target\n",
        "        \n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        \n",
        "        # Preprocessing\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        \n",
        "        # Model eğitimi\n",
        "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Test performansı\n",
        "        y_pred = self.model.predict(X_test_scaled)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        test_r2 = r2_score(y_test, y_pred)\n",
        "        \n",
        "        # Metadata\n",
        "        self.metadata = {\n",
        "            'model_type': 'RandomForestRegressor',\n",
        "            'version': '1.0.0',\n",
        "            'training_date': datetime.now().isoformat(),\n",
        "            'test_rmse': test_rmse,\n",
        "            'test_r2': test_r2,\n",
        "            'feature_names': california_housing.feature_names.tolist(),\n",
        "            'input_shape': X.shape[1],\n",
        "            'target_name': 'house_value'\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Model eğitildi!\")\n",
        "        print(f\"📊 Test RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"📊 Test R²: {test_r2:.4f}\")\n",
        "        \n",
        "        return X_test, y_test\n",
        "    \n",
        "    def save_model(self, version=\"v1\"):\n",
        "        \"\"\"Modeli ve preprocessing pipeline'ını kaydet\"\"\"\n",
        "        version_dir = self.model_dir / version\n",
        "        version_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        # Model kaydet\n",
        "        model_path = version_dir / \"model.pkl\"\n",
        "        joblib.dump(self.model, model_path)\n",
        "        \n",
        "        # Scaler kaydet\n",
        "        scaler_path = version_dir / \"scaler.pkl\"\n",
        "        joblib.dump(self.scaler, scaler_path)\n",
        "        \n",
        "        # Metadata kaydet\n",
        "        metadata_path = version_dir / \"metadata.json\"\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(self.metadata, f, indent=2)\n",
        "        \n",
        "        print(f\"💾 Model kaydedildi: {version_dir}\")\n",
        "        print(f\"   📁 Model: {model_path}\")\n",
        "        print(f\"   📁 Scaler: {scaler_path}\")\n",
        "        print(f\"   📁 Metadata: {metadata_path}\")\n",
        "        \n",
        "        return version_dir\n",
        "    \n",
        "    def load_model(self, version=\"v1\"):\n",
        "        \"\"\"Kaydedilmiş modeli yükle\"\"\"\n",
        "        version_dir = self.model_dir / version\n",
        "        \n",
        "        if not version_dir.exists():\n",
        "            raise FileNotFoundError(f\"Model version {version} bulunamadı!\")\n",
        "        \n",
        "        # Model yükle\n",
        "        model_path = version_dir / \"model.pkl\"\n",
        "        self.model = joblib.load(model_path)\n",
        "        \n",
        "        # Scaler yükle\n",
        "        scaler_path = version_dir / \"scaler.pkl\"\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "        \n",
        "        # Metadata yükle\n",
        "        metadata_path = version_dir / \"metadata.json\"\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            self.metadata = json.load(f)\n",
        "        \n",
        "        print(f\"📥 Model yüklendi: {version}\")\n",
        "        print(f\"📊 Model Type: {self.metadata['model_type']}\")\n",
        "        print(f\"📊 Version: {self.metadata['version']}\")\n",
        "        print(f\"📊 Test R²: {self.metadata['test_r2']:.4f}\")\n",
        "        \n",
        "        return self.model, self.scaler, self.metadata\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Tahmin yap\"\"\"\n",
        "        if hasattr(X, 'values'):\n",
        "            X = X.values\n",
        "        \n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "# Model paketi oluştur\n",
        "packager = ModelPackager()\n",
        "X_test, y_test = packager.prepare_model()\n",
        "model_version_dir = packager.save_model(\"v1\")\n",
        "\n",
        "print(\"\\n✅ Model packaging tamamlandı!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## 6. Özet ve Sonuçlar\n",
        "\n",
        "### 🎯 Bu Bölümde Neler Öğrendik?\n",
        "\n",
        "1. **Model Packaging**: Modelleri production-ready hale getirme\n",
        "2. **REST API Development**: FastAPI ile profesyonel API geliştirme\n",
        "3. **API Testing**: Kapsamlı test stratejileri\n",
        "4. **Docker Containerization**: Modelleri containerize etme\n",
        "5. **Load Testing**: Performance ve scalability analizi\n",
        "6. **Monitoring**: System health ve performance tracking\n",
        "\n",
        "### 📊 Deployment Best Practices:\n",
        "\n",
        "- **Model Versioning**: Her model versiyonunu ayrı dizinlerde saklama\n",
        "- **Error Handling**: Comprehensive hata yönetimi\n",
        "- **Health Checks**: System durumu monitoring\n",
        "- **Load Testing**: Production öncesi performance testi\n",
        "- **Documentation**: API documentation (FastAPI Swagger)\n",
        "- **Containerization**: Docker ile portable deployment\n",
        "\n",
        "### 🚀 Production Deployment Checklist:\n",
        "\n",
        "#### ✅ Model Hazırlığı\n",
        "- [ ] Model eğitildi ve test edildi\n",
        "- [ ] Preprocessing pipeline kaydedildi\n",
        "- [ ] Model metadata oluşturuldu\n",
        "- [ ] Model versioning sistemi kuruldu\n",
        "\n",
        "#### ✅ API Development\n",
        "- [ ] FastAPI application oluşturuldu\n",
        "- [ ] Input validation implement edildi\n",
        "- [ ] Error handling eklendi\n",
        "- [ ] Health check endpoint'i eklendi\n",
        "- [ ] API documentation hazırlandı\n",
        "\n",
        "#### ✅ Testing\n",
        "- [ ] Unit testler yazıldı\n",
        "- [ ] Integration testler yapıldı\n",
        "- [ ] Load testing tamamlandı\n",
        "- [ ] Error scenarios test edildi\n",
        "\n",
        "#### ✅ Deployment\n",
        "- [ ] Dockerfile oluşturuldu\n",
        "- [ ] Docker Compose konfigürasyonu hazırlandı\n",
        "- [ ] Environment variables tanımlandı\n",
        "- [ ] Health checks konfigüre edildi\n",
        "\n",
        "#### ✅ Monitoring\n",
        "- [ ] Performance metrics toplanıyor\n",
        "- [ ] Error logging aktif\n",
        "- [ ] Health monitoring kuruldu\n",
        "- [ ] Alerting sistemi aktif\n",
        "\n",
        "### 💡 Advanced Deployment Strategies:\n",
        "\n",
        "1. **Blue-Green Deployment**: Zero-downtime deployment\n",
        "2. **Canary Deployment**: Gradual rollout\n",
        "3. **A/B Testing**: Model comparison in production\n",
        "4. **Auto-scaling**: Traffic'e göre scaling\n",
        "5. **Circuit Breaker**: Error durumunda koruma\n",
        "6. **Rate Limiting**: API abuse koruması\n",
        "\n",
        "### 🔧 Production Tools:\n",
        "\n",
        "- **Container Orchestration**: Kubernetes, Docker Swarm\n",
        "- **API Gateway**: Kong, Ambassador, AWS API Gateway\n",
        "- **Monitoring**: Prometheus, Grafana, ELK Stack\n",
        "- **CI/CD**: Jenkins, GitLab CI, GitHub Actions\n",
        "- **Cloud Platforms**: AWS, Azure, GCP\n",
        "- **Load Balancing**: Nginx, HAProxy, AWS ALB\n",
        "\n",
        "### 📈 Sonraki Adımlar:\n",
        "\n",
        "1. **Level 6 - Monitoring**: Model performance monitoring\n",
        "2. **A/B Testing**: Farklı model versiyonlarını test etme\n",
        "3. **Automated Retraining**: Data drift detection ve otomatik model güncelleme\n",
        "4. **Multi-model Serving**: Birden fazla modeli aynı API'de servis etme\n",
        "\n",
        "---\n",
        "\n",
        "**Level 5 Tamamlandı! 🎉**\n",
        "\n",
        "Artık ML modellerinizi production ortamında güvenle deploy edebilir, test edebilir ve monitor edebilirsiniz!\n",
        "\n",
        "### 📚 Ek Kaynaklar:\n",
        "\n",
        "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
        "- [Docker Best Practices](https://docs.docker.com/develop/best-practices/)\n",
        "- [MLOps Deployment Patterns](https://ml-ops.org/content/deployment-patterns)\n",
        "- [Model Serving Strategies](https://developers.google.com/machine-learning/guides/rules-of-ml)\n",
        "\n",
        "**🚀 Production'a hazır ML servisi oluşturdunuz!**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. REST API Development\n",
        "\n",
        "FastAPI kullanarak model servisi oluşturacağız:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelService:\n",
        "    \"\"\"Model servisi için sınıf\"\"\"\n",
        "    \n",
        "    def __init__(self, model_version=\"v1\"):\n",
        "        self.packager = ModelPackager()\n",
        "        self.model, self.scaler, self.metadata = self.packager.load_model(model_version)\n",
        "        self.prediction_count = 0\n",
        "        self.start_time = time.time()\n",
        "    \n",
        "    def predict_single(self, features):\n",
        "        \"\"\"Tek tahmin yap\"\"\"\n",
        "        try:\n",
        "            # Feature validation\n",
        "            if len(features) != self.metadata['input_shape']:\n",
        "                raise ValueError(f\"Expected {self.metadata['input_shape']} features, got {len(features)}\")\n",
        "            \n",
        "            # Prediction\n",
        "            X = np.array(features).reshape(1, -1)\n",
        "            prediction = self.packager.predict(X)[0]\n",
        "            \n",
        "            self.prediction_count += 1\n",
        "            \n",
        "            return {\n",
        "                'prediction': float(prediction),\n",
        "                'model_version': self.metadata['version'],\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'prediction_id': self.prediction_count\n",
        "            }\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': str(e),\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "    \n",
        "    def predict_batch(self, features_list):\n",
        "        \"\"\"Batch tahmin yap\"\"\"\n",
        "        try:\n",
        "            predictions = []\n",
        "            for features in features_list:\n",
        "                result = self.predict_single(features)\n",
        "                predictions.append(result)\n",
        "            \n",
        "            return {\n",
        "                'predictions': predictions,\n",
        "                'batch_size': len(features_list),\n",
        "                'model_version': self.metadata['version'],\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': str(e),\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "    \n",
        "    def get_health(self):\n",
        "        \"\"\"Health check\"\"\"\n",
        "        uptime = time.time() - self.start_time\n",
        "        \n",
        "        return {\n",
        "            'status': 'healthy',\n",
        "            'uptime_seconds': uptime,\n",
        "            'total_predictions': self.prediction_count,\n",
        "            'model_version': self.metadata['version'],\n",
        "            'model_type': self.metadata['model_type'],\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        \"\"\"Model bilgilerini döndür\"\"\"\n",
        "        return {\n",
        "            'metadata': self.metadata,\n",
        "            'service_stats': {\n",
        "                'uptime_seconds': time.time() - self.start_time,\n",
        "                'total_predictions': self.prediction_count\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Model servisini başlat\n",
        "model_service = ModelService(\"v1\")\n",
        "\n",
        "print(\"🚀 Model servisi hazır!\")\n",
        "print(f\"📊 Model: {model_service.metadata['model_type']}\")\n",
        "print(f\"📊 Version: {model_service.metadata['version']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### FastAPI Application Oluşturma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pydantic modelleri\n",
        "class PredictionRequest(BaseModel):\n",
        "    features: list\n",
        "    \n",
        "class BatchPredictionRequest(BaseModel):\n",
        "    features_list: list\n",
        "\n",
        "# FastAPI app oluştur\n",
        "def create_fastapi_app():\n",
        "    app = FastAPI(\n",
        "        title=\"🏠 California Housing Price Predictor\",\n",
        "        description=\"Machine Learning model service for house price prediction\",\n",
        "        version=\"1.0.0\"\n",
        "    )\n",
        "    \n",
        "    # Global model service\n",
        "    service = ModelService(\"v1\")\n",
        "    \n",
        "    @app.get(\"/\")\n",
        "    async def root():\n",
        "        return {\n",
        "            \"message\": \"🏠 California Housing Price Predictor API\",\n",
        "            \"version\": \"1.0.0\",\n",
        "            \"model_version\": service.metadata['version'],\n",
        "            \"docs\": \"/docs\"\n",
        "        }\n",
        "    \n",
        "    @app.get(\"/health\")\n",
        "    async def health_check():\n",
        "        return service.get_health()\n",
        "    \n",
        "    @app.get(\"/model/info\")\n",
        "    async def model_info():\n",
        "        return service.get_model_info()\n",
        "    \n",
        "    @app.post(\"/predict\")\n",
        "    async def predict(request: PredictionRequest):\n",
        "        result = service.predict_single(request.features)\n",
        "        if 'error' in result:\n",
        "            raise HTTPException(status_code=400, detail=result['error'])\n",
        "        return result\n",
        "    \n",
        "    @app.post(\"/predict/batch\")\n",
        "    async def predict_batch(request: BatchPredictionRequest):\n",
        "        result = service.predict_batch(request.features_list)\n",
        "        if 'error' in result:\n",
        "            raise HTTPException(status_code=400, detail=result['error'])\n",
        "        return result\n",
        "    \n",
        "    return app\n",
        "\n",
        "# API app'i oluştur\n",
        "api_app = create_fastapi_app()\n",
        "\n",
        "print(\"🌐 FastAPI application oluşturuldu!\")\n",
        "print(\"📖 API Documentation: http://localhost:8000/docs\")\n",
        "print(\"🏥 Health Check: http://localhost:8000/health\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. API Testing ve Validation\n",
        "\n",
        "API'mizi test edelim ve örnek tahminler yapalım:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API testi için örnek veriler hazırlayalım\n",
        "class APITester:\n",
        "    \"\"\"API test sınıfı\"\"\"\n",
        "    \n",
        "    def __init__(self, service):\n",
        "        self.service = service\n",
        "        self.test_results = {}\n",
        "    \n",
        "    def test_single_prediction(self):\n",
        "        \"\"\"Tek tahmin testi\"\"\"\n",
        "        print(\"🔍 Tek tahmin testi...\")\n",
        "        \n",
        "        # Test verisinden örnek al\n",
        "        sample_features = X_test.iloc[0].tolist()\n",
        "        actual_value = y_test.iloc[0]\n",
        "        \n",
        "        # Tahmin yap\n",
        "        result = self.service.predict_single(sample_features)\n",
        "        \n",
        "        if 'error' not in result:\n",
        "            predicted_value = result['prediction']\n",
        "            error = abs(predicted_value - actual_value)\n",
        "            \n",
        "            print(f\"✅ Tek tahmin başarılı!\")\n",
        "            print(f\"   📊 Gerçek değer: ${actual_value:.2f}00k\")\n",
        "            print(f\"   📊 Tahmin değer: ${predicted_value:.2f}00k\")\n",
        "            print(f\"   📊 Hata: ${error:.2f}00k\")\n",
        "            print(f\"   🆔 Prediction ID: {result['prediction_id']}\")\n",
        "            \n",
        "            self.test_results['single_prediction'] = {\n",
        "                'success': True,\n",
        "                'actual': actual_value,\n",
        "                'predicted': predicted_value,\n",
        "                'error': error\n",
        "            }\n",
        "        else:\n",
        "            print(f\"❌ Tek tahmin hatası: {result['error']}\")\n",
        "            self.test_results['single_prediction'] = {'success': False, 'error': result['error']}\n",
        "    \n",
        "    def test_batch_prediction(self, batch_size=5):\n",
        "        \"\"\"Batch tahmin testi\"\"\"\n",
        "        print(f\"\\n🔍 Batch tahmin testi ({batch_size} örnek)...\")\n",
        "        \n",
        "        # Test verisinden batch al\n",
        "        batch_features = X_test.iloc[:batch_size].values.tolist()\n",
        "        actual_values = y_test.iloc[:batch_size].tolist()\n",
        "        \n",
        "        # Batch tahmin yap\n",
        "        result = self.service.predict_batch(batch_features)\n",
        "        \n",
        "        if 'error' not in result:\n",
        "            predictions = [pred['prediction'] for pred in result['predictions']]\n",
        "            errors = [abs(pred - actual) for pred, actual in zip(predictions, actual_values)]\n",
        "            mean_error = np.mean(errors)\n",
        "            \n",
        "            print(f\"✅ Batch tahmin başarılı!\")\n",
        "            print(f\"   📊 Batch size: {result['batch_size']}\")\n",
        "            print(f\"   📊 Ortalama hata: ${mean_error:.2f}00k\")\n",
        "            print(f\"   📊 Min hata: ${min(errors):.2f}00k\")\n",
        "            print(f\"   📊 Max hata: ${max(errors):.2f}00k\")\n",
        "            \n",
        "            self.test_results['batch_prediction'] = {\n",
        "                'success': True,\n",
        "                'batch_size': batch_size,\n",
        "                'mean_error': mean_error,\n",
        "                'predictions': predictions,\n",
        "                'actual_values': actual_values\n",
        "            }\n",
        "        else:\n",
        "            print(f\"❌ Batch tahmin hatası: {result['error']}\")\n",
        "            self.test_results['batch_prediction'] = {'success': False, 'error': result['error']}\n",
        "    \n",
        "    def test_health_check(self):\n",
        "        \"\"\"Health check testi\"\"\"\n",
        "        print(f\"\\n🏥 Health check testi...\")\n",
        "        \n",
        "        health = self.service.get_health()\n",
        "        \n",
        "        print(f\"✅ Health check sonuçları:\")\n",
        "        print(f\"   📊 Status: {health['status']}\")\n",
        "        print(f\"   📊 Uptime: {health['uptime_seconds']:.2f} saniye\")\n",
        "        print(f\"   📊 Total predictions: {health['total_predictions']}\")\n",
        "        print(f\"   📊 Model version: {health['model_version']}\")\n",
        "        \n",
        "        self.test_results['health_check'] = health\n",
        "    \n",
        "    def test_model_info(self):\n",
        "        \\\"\\\"\\\"Model info testi\\\"\\\"\\\"\n",
        "        print(f\\\"\\\\n📋 Model info testi...\\\")\n",
        "        \n",
        "        info = self.service.get_model_info()\n",
        "        \n",
        "        print(f\\\"✅ Model bilgileri:\\\")\n",
        "        print(f\\\"   📊 Model type: {info['metadata']['model_type']}\\\")\n",
        "        print(f\\\"   📊 Version: {info['metadata']['version']}\\\")\n",
        "        print(f\\\"   📊 Training date: {info['metadata']['training_date'][:10]}\\\")\n",
        "        print(f\\\"   📊 Test R²: {info['metadata']['test_r2']:.4f}\\\")\n",
        "        print(f\\\"   📊 Input features: {info['metadata']['input_shape']}\\\")\n",
        "        \n",
        "        self.test_results['model_info'] = info\n",
        "    \n",
        "    def test_error_handling(self):\n",
        "        \\\"\\\"\\\"Error handling testi\\\"\\\"\\\"\n",
        "        print(f\\\"\\\\n⚠️ Error handling testi...\\\")\n",
        "        \n",
        "        # Yanlış feature sayısı ile test\n",
        "        wrong_features = [1, 2, 3]  # 8 olması gerekiyor\n",
        "        result = self.service.predict_single(wrong_features)\n",
        "        \n",
        "        if 'error' in result:\n",
        "            print(f\\\"✅ Error handling çalışıyor: {result['error']}\\\")\n",
        "            self.test_results['error_handling'] = {'success': True, 'error_message': result['error']}\n",
        "        else:\n",
        "            print(f\\\"❌ Error handling çalışmıyor!\\\")\n",
        "            self.test_results['error_handling'] = {'success': False}\n",
        "    \n",
        "    def run_all_tests(self):\n",
        "        \\\"\\\"\\\"Tüm testleri çalıştır\\\"\\\"\\\"\n",
        "        print(\\\"🧪 API TESTLER BAŞLATIYOR...\\\")\n",
        "        print(\\\"=\\\" * 50)\n",
        "        \n",
        "        self.test_single_prediction()\n",
        "        self.test_batch_prediction()\n",
        "        self.test_health_check()\n",
        "        self.test_model_info()\n",
        "        self.test_error_handling()\n",
        "        \n",
        "        print(\\\"\\\\n\\\" + \\\"=\\\" * 50)\n",
        "        print(\\\"✅ Tüm testler tamamlandı!\\\")\n",
        "        \n",
        "        return self.test_results\n",
        "\n",
        "# API testlerini çalıştır\n",
        "tester = APITester(model_service)\n",
        "test_results = tester.run_all_tests()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Docker Containerization\n",
        "\n",
        "Modelimizi Docker container'ında paketleyeceğiz:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DockerDeployment:\n",
        "    \"\"\"Docker deployment sınıfı\"\"\"\n",
        "    \n",
        "    def __init__(self, app_name=\"housing-predictor\"):\n",
        "        self.app_name = app_name\n",
        "        self.dockerfile_content = None\n",
        "        self.requirements_content = None\n",
        "        self.app_content = None\n",
        "    \n",
        "    def generate_requirements(self):\n",
        "        \"\"\"Requirements.txt dosyası oluştur\"\"\"\n",
        "        self.requirements_content = \"\"\"fastapi==0.104.1\n",
        "uvicorn==0.24.0\n",
        "pandas==2.1.4\n",
        "numpy==1.24.3\n",
        "scikit-learn==1.3.2\n",
        "joblib==1.3.2\n",
        "pydantic==2.5.0\n",
        "\"\"\"\n",
        "        \n",
        "        # Requirements dosyasını yaz\n",
        "        with open(\"requirements.txt\", \"w\") as f:\n",
        "            f.write(self.requirements_content)\n",
        "        \n",
        "        print(\"📦 requirements.txt oluşturuldu!\")\n",
        "        return self.requirements_content\n",
        "    \n",
        "    def generate_app_file(self):\n",
        "        \"\"\"Standalone app.py dosyası oluştur\"\"\"\n",
        "        self.app_content = '''import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "# Pydantic modelleri\n",
        "class PredictionRequest(BaseModel):\n",
        "    features: list\n",
        "\n",
        "class BatchPredictionRequest(BaseModel):\n",
        "    features_list: list\n",
        "\n",
        "class ModelService:\n",
        "    \"\"\"Model servisi\"\"\"\n",
        "    \n",
        "    def __init__(self, model_dir=\"models\", version=\"v1\"):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.version = version\n",
        "        self.prediction_count = 0\n",
        "        self.start_time = datetime.now().timestamp()\n",
        "        self.load_model()\n",
        "    \n",
        "    def load_model(self):\n",
        "        \"\"\"Modeli yükle\"\"\"\n",
        "        version_dir = self.model_dir / self.version\n",
        "        \n",
        "        # Model yükle\n",
        "        model_path = version_dir / \"model.pkl\"\n",
        "        self.model = joblib.load(model_path)\n",
        "        \n",
        "        # Scaler yükle\n",
        "        scaler_path = version_dir / \"scaler.pkl\"\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "        \n",
        "        # Metadata yükle\n",
        "        metadata_path = version_dir / \"metadata.json\"\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            self.metadata = json.load(f)\n",
        "    \n",
        "    def predict(self, features):\n",
        "        \"\"\"Tahmin yap\"\"\"\n",
        "        X = np.array(features).reshape(1, -1)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        prediction = self.model.predict(X_scaled)[0]\n",
        "        \n",
        "        self.prediction_count += 1\n",
        "        \n",
        "        return {\n",
        "            'prediction': float(prediction),\n",
        "            'model_version': self.metadata['version'],\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'prediction_id': self.prediction_count\n",
        "        }\n",
        "\n",
        "# FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"🏠 Housing Price Predictor\",\n",
        "    description=\"ML model service\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Model servisi\n",
        "service = ModelService()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\n",
        "        \"message\": \"🏠 Housing Price Predictor API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"status\": \"healthy\"\n",
        "    }\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"uptime\": datetime.now().timestamp() - service.start_time,\n",
        "        \"predictions\": service.prediction_count\n",
        "    }\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(request: PredictionRequest):\n",
        "    try:\n",
        "        if len(request.features) != service.metadata['input_shape']:\n",
        "            raise HTTPException(400, f\"Expected {service.metadata['input_shape']} features\")\n",
        "        \n",
        "        return service.predict(request.features)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(400, str(e))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "'''\n",
        "        \n",
        "        # App dosyasını yaz\n",
        "        with open(\"app.py\", \"w\") as f:\n",
        "            f.write(self.app_content)\n",
        "        \n",
        "        print(\"🐍 app.py oluşturuldu!\")\n",
        "        return self.app_content\n",
        "    \n",
        "    def generate_dockerfile(self):\n",
        "        \"\"\"Dockerfile oluştur\"\"\"\n",
        "        self.dockerfile_content = f\"\"\"# Python 3.9 slim image kullan\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Working directory ayarla\n",
        "WORKDIR /app\n",
        "\n",
        "# System dependencies\n",
        "RUN apt-get update && apt-get install -y \\\\\n",
        "    gcc \\\\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Python dependencies\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Uygulama dosyalarını kopyala\n",
        "COPY app.py .\n",
        "COPY models/ ./models/\n",
        "\n",
        "# Port expose et\n",
        "EXPOSE 8000\n",
        "\n",
        "# Health check ekle\n",
        "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\\\n",
        "    CMD curl -f http://localhost:8000/health || exit 1\n",
        "\n",
        "# Uygulamayı başlat\n",
        "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "\"\"\"\n",
        "        \n",
        "        # Dockerfile'ı yaz\n",
        "        with open(\"Dockerfile\", \"w\") as f:\n",
        "            f.write(self.dockerfile_content)\n",
        "        \n",
        "        print(\"🐳 Dockerfile oluşturuldu!\")\n",
        "        return self.dockerfile_content\n",
        "    \n",
        "    def generate_docker_compose(self):\n",
        "        \"\"\"Docker Compose dosyası oluştur\"\"\"\n",
        "        compose_content = f\"\"\"version: '3.8'\n",
        "\n",
        "services:\n",
        "  {self.app_name}:\n",
        "    build: .\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    environment:\n",
        "      - ENV=production\n",
        "    restart: unless-stopped\n",
        "    healthcheck:\n",
        "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
        "      interval: 30s\n",
        "      timeout: 10s\n",
        "      retries: 3\n",
        "      start_period: 40s\n",
        "\"\"\"\n",
        "        \n",
        "        # Docker compose dosyasını yaz\n",
        "        with open(\"docker-compose.yml\", \"w\") as f:\n",
        "            f.write(compose_content)\n",
        "        \n",
        "        print(\"🔧 docker-compose.yml oluşturuldu!\")\n",
        "        return compose_content\n",
        "    \n",
        "    def generate_all_files(self):\n",
        "        \"\"\"Tüm Docker dosyalarını oluştur\"\"\"\n",
        "        print(\"🏗️ Docker deployment dosyaları oluşturuluyor...\")\n",
        "        \n",
        "        self.generate_requirements()\n",
        "        self.generate_app_file()\n",
        "        self.generate_dockerfile()\n",
        "        self.generate_docker_compose()\n",
        "        \n",
        "        print(\"\\n✅ Docker deployment hazır!\")\n",
        "        print(\"🚀 Çalıştırmak için:\")\n",
        "        print(\"   docker-compose up --build\")\n",
        "        print(\"📖 API docs: http://localhost:8000/docs\")\n",
        "        \n",
        "        return {\n",
        "            'requirements': self.requirements_content,\n",
        "            'app': self.app_content,\n",
        "            'dockerfile': self.dockerfile_content\n",
        "        }\n",
        "\n",
        "# Docker deployment oluştur\n",
        "docker_deploy = DockerDeployment(\"housing-predictor\")\n",
        "docker_files = docker_deploy.generate_all_files()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Load Testing ve Performance Monitoring\n",
        "\n",
        "API'mizin performansını test edelim:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LoadTester:\n",
        "    \"\"\"Load testing sınıfı\"\"\"\n",
        "    \n",
        "    def __init__(self, service):\n",
        "        self.service = service\n",
        "        self.test_results = {}\n",
        "        \n",
        "    def single_request_benchmark(self, num_requests=100):\n",
        "        \"\"\"Tek request benchmark testi\"\"\"\n",
        "        print(f\"⚡ Tek request benchmark ({num_requests} istek)...\")\n",
        "        \n",
        "        # Test verisi hazırla\n",
        "        sample_features = X_test.iloc[0].tolist()\n",
        "        \n",
        "        start_time = time.time()\n",
        "        successful_requests = 0\n",
        "        failed_requests = 0\n",
        "        response_times = []\n",
        "        \n",
        "        for i in range(num_requests):\n",
        "            request_start = time.time()\n",
        "            \n",
        "            try:\n",
        "                result = self.service.predict_single(sample_features)\n",
        "                request_end = time.time()\n",
        "                \n",
        "                if 'error' not in result:\n",
        "                    successful_requests += 1\n",
        "                    response_times.append((request_end - request_start) * 1000)  # ms\n",
        "                else:\n",
        "                    failed_requests += 1\n",
        "                    \n",
        "            except Exception as e:\n",
        "                failed_requests += 1\n",
        "        \n",
        "        total_time = time.time() - start_time\n",
        "        avg_response_time = np.mean(response_times) if response_times else 0\n",
        "        requests_per_second = successful_requests / total_time if total_time > 0 else 0\n",
        "        \n",
        "        print(f\"✅ Tek request benchmark sonuçları:\")\n",
        "        print(f\"   📊 Toplam istek: {num_requests}\")\n",
        "        print(f\"   📊 Başarılı: {successful_requests}\")\n",
        "        print(f\"   📊 Başarısız: {failed_requests}\")\n",
        "        print(f\"   📊 Ortalama yanıt süresi: {avg_response_time:.2f} ms\")\n",
        "        print(f\"   📊 Min yanıt süresi: {min(response_times):.2f} ms\")\n",
        "        print(f\"   📊 Max yanıt süresi: {max(response_times):.2f} ms\")\n",
        "        print(f\"   📊 Request/saniye: {requests_per_second:.2f}\")\n",
        "        \n",
        "        self.test_results['single_request'] = {\n",
        "            'total_requests': num_requests,\n",
        "            'successful': successful_requests,\n",
        "            'failed': failed_requests,\n",
        "            'avg_response_time_ms': avg_response_time,\n",
        "            'min_response_time_ms': min(response_times) if response_times else 0,\n",
        "            'max_response_time_ms': max(response_times) if response_times else 0,\n",
        "            'requests_per_second': requests_per_second,\n",
        "            'total_time_seconds': total_time\n",
        "        }\n",
        "        \n",
        "        return self.test_results['single_request']\n",
        "    \n",
        "    def concurrent_request_benchmark(self, num_threads=10, requests_per_thread=10):\n",
        "        \"\"\"Concurrent request benchmark testi\"\"\"\n",
        "        print(f\"🚀 Concurrent benchmark ({num_threads} thread, {requests_per_thread} istek/thread)...\")\n",
        "        \n",
        "        sample_features = X_test.iloc[0].tolist()\n",
        "        all_response_times = []\n",
        "        successful_requests = 0\n",
        "        failed_requests = 0\n",
        "        \n",
        "        def worker():\n",
        "            nonlocal successful_requests, failed_requests\n",
        "            thread_response_times = []\n",
        "            \n",
        "            for _ in range(requests_per_thread):\n",
        "                request_start = time.time()\n",
        "                \n",
        "                try:\n",
        "                    result = self.service.predict_single(sample_features)\n",
        "                    request_end = time.time()\n",
        "                    \n",
        "                    if 'error' not in result:\n",
        "                        successful_requests += 1\n",
        "                        thread_response_times.append((request_end - request_start) * 1000)\n",
        "                    else:\n",
        "                        failed_requests += 1\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    failed_requests += 1\n",
        "            \n",
        "            all_response_times.extend(thread_response_times)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Thread pool ile test çalıştır\n",
        "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "            futures = [executor.submit(worker) for _ in range(num_threads)]\n",
        "            \n",
        "            # Tüm thread'lerin bitmesini bekle\n",
        "            for future in futures:\n",
        "                future.result()\n",
        "        \n",
        "        total_time = time.time() - start_time\n",
        "        total_requests = num_threads * requests_per_thread\n",
        "        avg_response_time = np.mean(all_response_times) if all_response_times else 0\n",
        "        requests_per_second = successful_requests / total_time if total_time > 0 else 0\n",
        "        \n",
        "        print(f\"✅ Concurrent benchmark sonuçları:\")\n",
        "        print(f\"   📊 Toplam thread: {num_threads}\")\n",
        "        print(f\"   📊 Thread başına istek: {requests_per_thread}\")\n",
        "        print(f\"   📊 Toplam istek: {total_requests}\")\n",
        "        print(f\"   📊 Başarılı: {successful_requests}\")\n",
        "        print(f\"   📊 Başarısız: {failed_requests}\")\n",
        "        print(f\"   📊 Ortalama yanıt süresi: {avg_response_time:.2f} ms\")\n",
        "        print(f\"   📊 Request/saniye: {requests_per_second:.2f}\")\n",
        "        \n",
        "        self.test_results['concurrent'] = {\n",
        "            'num_threads': num_threads,\n",
        "            'requests_per_thread': requests_per_thread,\n",
        "            'total_requests': total_requests,\n",
        "            'successful': successful_requests,\n",
        "            'failed': failed_requests,\n",
        "            'avg_response_time_ms': avg_response_time,\n",
        "            'requests_per_second': requests_per_second,\n",
        "            'total_time_seconds': total_time\n",
        "        }\n",
        "        \n",
        "        return self.test_results['concurrent']\n",
        "    \n",
        "    def memory_usage_test(self, num_predictions=1000):\n",
        "        \"\"\"Memory usage testi\"\"\"\n",
        "        print(f\"💾 Memory usage testi ({num_predictions} tahmin)...\")\n",
        "        \n",
        "        # Başlangıç memory kullanımı\n",
        "        process = psutil.Process()\n",
        "        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
        "        \n",
        "        sample_features = X_test.iloc[0].tolist()\n",
        "        \n",
        "        # Tahminler yap\n",
        "        for i in range(num_predictions):\n",
        "            result = self.service.predict_single(sample_features)\n",
        "            \n",
        "            # Her 100 tahminde bir memory kontrolü\n",
        "            if i % 100 == 0:\n",
        "                current_memory = process.memory_info().rss / 1024 / 1024\n",
        "                print(f\"   📊 {i} tahmin - Memory: {current_memory:.2f} MB\")\n",
        "        \n",
        "        # Final memory kullanımı\n",
        "        final_memory = process.memory_info().rss / 1024 / 1024\n",
        "        memory_increase = final_memory - initial_memory\n",
        "        \n",
        "        print(f\"✅ Memory usage sonuçları:\")\n",
        "        print(f\"   📊 Başlangıç memory: {initial_memory:.2f} MB\")\n",
        "        print(f\"   📊 Final memory: {final_memory:.2f} MB\")\n",
        "        print(f\"   📊 Memory artışı: {memory_increase:.2f} MB\")\n",
        "        print(f\"   📊 Tahmin başına memory: {memory_increase/num_predictions*1000:.4f} KB\")\n",
        "        \n",
        "        self.test_results['memory'] = {\n",
        "            'initial_memory_mb': initial_memory,\n",
        "            'final_memory_mb': final_memory,\n",
        "            'memory_increase_mb': memory_increase,\n",
        "            'memory_per_prediction_kb': memory_increase/num_predictions*1000,\n",
        "            'num_predictions': num_predictions\n",
        "        }\n",
        "        \n",
        "        return self.test_results['memory']\n",
        "    \n",
        "    def plot_performance_results(self):\n",
        "        \"\"\"Performance sonuçlarını görselleştir\"\"\"\n",
        "        if not self.test_results:\n",
        "            print(\"❌ Henüz test yapılmamış!\")\n",
        "            return\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Response time comparison\n",
        "        if 'single_request' in self.test_results and 'concurrent' in self.test_results:\n",
        "            response_times = [\n",
        "                self.test_results['single_request']['avg_response_time_ms'],\n",
        "                self.test_results['concurrent']['avg_response_time_ms']\n",
        "            ]\n",
        "            test_types = ['Single Thread', 'Concurrent']\n",
        "            \n",
        "            axes[0, 0].bar(test_types, response_times, alpha=0.7, color=['blue', 'orange'])\n",
        "            axes[0, 0].set_title('📊 Average Response Time')\n",
        "            axes[0, 0].set_ylabel('Response Time (ms)')\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for i, v in enumerate(response_times):\n",
        "                axes[0, 0].text(i, v + max(response_times)*0.01, f'{v:.2f} ms', \n",
        "                               ha='center', va='bottom')\n",
        "        \n",
        "        # Requests per second comparison\n",
        "        if 'single_request' in self.test_results and 'concurrent' in self.test_results:\n",
        "            rps_values = [\n",
        "                self.test_results['single_request']['requests_per_second'],\n",
        "                self.test_results['concurrent']['requests_per_second']\n",
        "            ]\n",
        "            \n",
        "            axes[0, 1].bar(test_types, rps_values, alpha=0.7, color=['green', 'red'])\n",
        "            axes[0, 1].set_title('🚀 Requests Per Second')\n",
        "            axes[0, 1].set_ylabel('Requests/Second')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for i, v in enumerate(rps_values):\n",
        "                axes[0, 1].text(i, v + max(rps_values)*0.01, f'{v:.2f}', \n",
        "                               ha='center', va='bottom')\n",
        "        \n",
        "        # Success rate\n",
        "        if 'single_request' in self.test_results:\n",
        "            single_success_rate = (self.test_results['single_request']['successful'] / \n",
        "                                 self.test_results['single_request']['total_requests'] * 100)\n",
        "            concurrent_success_rate = (self.test_results['concurrent']['successful'] / \n",
        "                                     self.test_results['concurrent']['total_requests'] * 100)\n",
        "            \n",
        "            success_rates = [single_success_rate, concurrent_success_rate]\n",
        "            \n",
        "            axes[1, 0].bar(test_types, success_rates, alpha=0.7, color=['lightgreen', 'lightcoral'])\n",
        "            axes[1, 0].set_title('✅ Success Rate')\n",
        "            axes[1, 0].set_ylabel('Success Rate (%)')\n",
        "            axes[1, 0].set_ylim(0, 105)\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for i, v in enumerate(success_rates):\n",
        "                axes[1, 0].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
        "        \n",
        "        # Memory usage\n",
        "        if 'memory' in self.test_results:\n",
        "            memory_data = self.test_results['memory']\n",
        "            memory_categories = ['Initial', 'Final', 'Increase']\n",
        "            memory_values = [\n",
        "                memory_data['initial_memory_mb'],\n",
        "                memory_data['final_memory_mb'],\n",
        "                memory_data['memory_increase_mb']\n",
        "            ]\n",
        "            \n",
        "            bars = axes[1, 1].bar(memory_categories, memory_values, alpha=0.7, \n",
        "                                color=['lightblue', 'orange', 'red'])\n",
        "            axes[1, 1].set_title('💾 Memory Usage')\n",
        "            axes[1, 1].set_ylabel('Memory (MB)')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for bar, value in zip(bars, memory_values):\n",
        "                axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(memory_values)*0.01,\n",
        "                               f'{value:.2f} MB', ha='center', va='bottom')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def run_all_tests(self):\n",
        "        \"\"\"Tüm performance testlerini çalıştır\"\"\"\n",
        "        print(\"⚡ LOAD TESTING BAŞLATIYOR...\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Single request benchmark\n",
        "        self.single_request_benchmark(num_requests=100)\n",
        "        print()\n",
        "        \n",
        "        # Concurrent benchmark\n",
        "        self.concurrent_request_benchmark(num_threads=5, requests_per_thread=20)\n",
        "        print()\n",
        "        \n",
        "        # Memory usage test\n",
        "        self.memory_usage_test(num_predictions=500)\n",
        "        print()\n",
        "        \n",
        "        # Results visualization\n",
        "        self.plot_performance_results()\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        print(\"✅ Tüm performance testleri tamamlandı!\")\n",
        "        \n",
        "        return self.test_results\n",
        "\n",
        "# Load testing çalıştır\n",
        "load_tester = LoadTester(model_service)\n",
        "performance_results = load_tester.run_all_tests()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Özet ve Sonuçlar\n",
        "\n",
        "### 🎯 Bu Bölümde Neler Öğrendik?\n",
        "\n",
        "1. **Model Packaging**: Modelleri production-ready hale getirme\n",
        "2. **REST API Development**: FastAPI ile profesyonel API geliştirme\n",
        "3. **API Testing**: Kapsamlı test stratejileri\n",
        "4. **Docker Containerization**: Modelleri containerize etme\n",
        "5. **Load Testing**: Performance ve scalability analizi\n",
        "6. **Monitoring**: System health ve performance tracking\n",
        "\n",
        "### 📊 Deployment Best Practices:\n",
        "\n",
        "- **Model Versioning**: Her model versiyonunu ayrı dizinlerde saklama\n",
        "- **Error Handling**: Comprehensive hata yönetimi\n",
        "- **Health Checks**: System durumu monitoring\n",
        "- **Load Testing**: Production öncesi performance testi\n",
        "- **Documentation**: API documentation (FastAPI Swagger)\n",
        "- **Containerization**: Docker ile portable deployment\n",
        "\n",
        "### 🚀 Production Deployment Checklist:\n",
        "\n",
        "#### ✅ Model Hazırlığı\n",
        "- [ ] Model eğitildi ve test edildi\n",
        "- [ ] Preprocessing pipeline kaydedildi\n",
        "- [ ] Model metadata oluşturuldu\n",
        "- [ ] Model versioning sistemi kuruldu\n",
        "\n",
        "#### ✅ API Development\n",
        "- [ ] FastAPI application oluşturuldu\n",
        "- [ ] Input validation implement edildi\n",
        "- [ ] Error handling eklendi\n",
        "- [ ] Health check endpoint'i eklendi\n",
        "- [ ] API documentation hazırlandı\n",
        "\n",
        "#### ✅ Testing\n",
        "- [ ] Unit testler yazıldı\n",
        "- [ ] Integration testler yapıldı\n",
        "- [ ] Load testing tamamlandı\n",
        "- [ ] Error scenarios test edildi\n",
        "\n",
        "#### ✅ Deployment\n",
        "- [ ] Dockerfile oluşturuldu\n",
        "- [ ] Docker Compose konfigürasyonu hazırlandı\n",
        "- [ ] Environment variables tanımlandı\n",
        "- [ ] Health checks konfigüre edildi\n",
        "\n",
        "#### ✅ Monitoring\n",
        "- [ ] Performance metrics toplanıyor\n",
        "- [ ] Error logging aktif\n",
        "- [ ] Health monitoring kuruldu\n",
        "- [ ] Alerting sistemi aktif\n",
        "\n",
        "### 💡 Advanced Deployment Strategies:\n",
        "\n",
        "1. **Blue-Green Deployment**: Zero-downtime deployment\n",
        "2. **Canary Deployment**: Gradual rollout\n",
        "3. **A/B Testing**: Model comparison in production\n",
        "4. **Auto-scaling**: Traffic'e göre scaling\n",
        "5. **Circuit Breaker**: Error durumunda koruma\n",
        "6. **Rate Limiting**: API abuse koruması\n",
        "\n",
        "### 🔧 Production Tools:\n",
        "\n",
        "- **Container Orchestration**: Kubernetes, Docker Swarm\n",
        "- **API Gateway**: Kong, Ambassador, AWS API Gateway\n",
        "- **Monitoring**: Prometheus, Grafana, ELK Stack\n",
        "- **CI/CD**: Jenkins, GitLab CI, GitHub Actions\n",
        "- **Cloud Platforms**: AWS, Azure, GCP\n",
        "- **Load Balancing**: Nginx, HAProxy, AWS ALB\n",
        "\n",
        "### 📈 Sonraki Adımlar:\n",
        "\n",
        "1. **Level 6 - Monitoring**: Model performance monitoring\n",
        "2. **A/B Testing**: Farklı model versiyonlarını test etme\n",
        "3. **Automated Retraining**: Data drift detection ve otomatik model güncelleme\n",
        "4. **Multi-model Serving**: Birden fazla modeli aynı API'de servis etme\n",
        "\n",
        "---\n",
        "\n",
        "**Level 5 Tamamlandı! 🎉**\n",
        "\n",
        "Artık ML modellerinizi production ortamında güvenle deploy edebilir, test edebilir ve monitor edebilirsiniz!\n",
        "\n",
        "### 📚 Ek Kaynaklar:\n",
        "\n",
        "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
        "- [Docker Best Practices](https://docs.docker.com/develop/best-practices/)\n",
        "- [MLOps Deployment Patterns](https://ml-ops.org/content/deployment-patterns)\n",
        "- [Model Serving Strategies](https://developers.google.com/machine-learning/guides/rules-of-ml)\n",
        "\n",
        "**🚀 Production'a hazır ML servisi oluşturdunuz!**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## 6. Özet ve Sonuçlar\n",
        "\n",
        "### 🎯 Bu Bölümde Neler Öğrendik?\n",
        "\n",
        "1. **Model Packaging**: Modelleri production-ready hale getirme\n",
        "2. **REST API Development**: FastAPI ile profesyonel API geliştirme\n",
        "3. **API Testing**: Kapsamlı test stratejileri\n",
        "4. **Docker Containerization**: Modelleri containerize etme\n",
        "5. **Load Testing**: Performance ve scalability analizi\n",
        "6. **Monitoring**: System health ve performance tracking\n",
        "\n",
        "### 📊 Deployment Best Practices:\n",
        "\n",
        "- **Model Versioning**: Her model versiyonunu ayrı dizinlerde saklama\n",
        "- **Error Handling**: Comprehensive hata yönetimi\n",
        "- **Health Checks**: System durumu monitoring\n",
        "- **Load Testing**: Production öncesi performance testi\n",
        "- **Documentation**: API documentation (FastAPI Swagger)\n",
        "- **Containerization**: Docker ile portable deployment\n",
        "\n",
        "### 🚀 Production Deployment Checklist:\n",
        "\n",
        "#### ✅ Model Hazırlığı\n",
        "- [ ] Model eğitildi ve test edildi\n",
        "- [ ] Preprocessing pipeline kaydedildi\n",
        "- [ ] Model metadata oluşturuldu\n",
        "- [ ] Model versioning sistemi kuruldu\n",
        "\n",
        "#### ✅ API Development\n",
        "- [ ] FastAPI application oluşturuldu\n",
        "- [ ] Input validation implement edildi\n",
        "- [ ] Error handling eklendi\n",
        "- [ ] Health check endpoint'i eklendi\n",
        "- [ ] API documentation hazırlandı\n",
        "\n",
        "#### ✅ Testing\n",
        "- [ ] Unit testler yazıldı\n",
        "- [ ] Integration testler yapıldı\n",
        "- [ ] Load testing tamamlandı\n",
        "- [ ] Error scenarios test edildi\n",
        "\n",
        "#### ✅ Deployment\n",
        "- [ ] Dockerfile oluşturuldu\n",
        "- [ ] Docker Compose konfigürasyonu hazırlandı\n",
        "- [ ] Environment variables tanımlandı\n",
        "- [ ] Health checks konfigüre edildi\n",
        "\n",
        "#### ✅ Monitoring\n",
        "- [ ] Performance metrics toplanıyor\n",
        "- [ ] Error logging aktif\n",
        "- [ ] Health monitoring kuruldu\n",
        "- [ ] Alerting sistemi aktif\n",
        "\n",
        "### 💡 Advanced Deployment Strategies:\n",
        "\n",
        "1. **Blue-Green Deployment**: Zero-downtime deployment\n",
        "2. **Canary Deployment**: Gradual rollout\n",
        "3. **A/B Testing**: Model comparison in production\n",
        "4. **Auto-scaling**: Traffic'e göre scaling\n",
        "5. **Circuit Breaker**: Error durumunda koruma\n",
        "6. **Rate Limiting**: API abuse koruması\n",
        "\n",
        "### 🔧 Production Tools:\n",
        "\n",
        "- **Container Orchestration**: Kubernetes, Docker Swarm\n",
        "- **API Gateway**: Kong, Ambassador, AWS API Gateway\n",
        "- **Monitoring**: Prometheus, Grafana, ELK Stack\n",
        "- **CI/CD**: Jenkins, GitLab CI, GitHub Actions\n",
        "- **Cloud Platforms**: AWS, Azure, GCP\n",
        "- **Load Balancing**: Nginx, HAProxy, AWS ALB\n",
        "\n",
        "### 📈 Sonraki Adımlar:\n",
        "\n",
        "1. **Level 6 - Monitoring**: Model performance monitoring\n",
        "2. **A/B Testing**: Farklı model versiyonlarını test etme\n",
        "3. **Automated Retraining**: Data drift detection ve otomatik model güncelleme\n",
        "4. **Multi-model Serving**: Birden fazla modeli aynı API'de servis etme\n",
        "\n",
        "---\n",
        "\n",
        "**Level 5 Tamamlandı! 🎉**\n",
        "\n",
        "Artık ML modellerinizi production ortamında güvenle deploy edebilir, test edebilir ve monitor edebilirsiniz!\n",
        "\n",
        "### 📚 Ek Kaynaklar:\n",
        "\n",
        "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
        "- [Docker Best Practices](https://docs.docker.com/develop/best-practices/)\n",
        "- [MLOps Deployment Patterns](https://ml-ops.org/content/deployment-patterns)\n",
        "- [Model Serving Strategies](https://developers.google.com/machine-learning/guides/rules-of-ml)\n",
        "\n",
        "**🚀 Production'a hazır ML servisi oluşturdunuz!**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## 6. Özet ve Sonuçlar\n",
        "\n",
        "### 🎯 Bu Bölümde Neler Öğrendik?\n",
        "\n",
        "1. **Model Packaging**: Modelleri production-ready hale getirme\n",
        "2. **REST API Development**: FastAPI ile profesyonel API geliştirme\n",
        "3. **API Testing**: Kapsamlı test stratejileri\n",
        "4. **Docker Containerization**: Modelleri containerize etme\n",
        "5. **Load Testing**: Performance ve scalability analizi\n",
        "6. **Monitoring**: System health ve performance tracking\n",
        "\n",
        "### 📊 Deployment Best Practices:\n",
        "\n",
        "- **Model Versioning**: Her model versiyonunu ayrı dizinlerde saklama\n",
        "- **Error Handling**: Comprehensive hata yönetimi\n",
        "- **Health Checks**: System durumu monitoring\n",
        "- **Load Testing**: Production öncesi performance testi\n",
        "- **Documentation**: API documentation (FastAPI Swagger)\n",
        "- **Containerization**: Docker ile portable deployment\n",
        "\n",
        "### 🚀 Production Deployment Checklist:\n",
        "\n",
        "#### ✅ Model Hazırlığı\n",
        "- [ ] Model eğitildi ve test edildi\n",
        "- [ ] Preprocessing pipeline kaydedildi\n",
        "- [ ] Model metadata oluşturuldu\n",
        "- [ ] Model versioning sistemi kuruldu\n",
        "\n",
        "#### ✅ API Development\n",
        "- [ ] FastAPI application oluşturuldu\n",
        "- [ ] Input validation implement edildi\n",
        "- [ ] Error handling eklendi\n",
        "- [ ] Health check endpoint'i eklendi\n",
        "- [ ] API documentation hazırlandı\n",
        "\n",
        "#### ✅ Testing\n",
        "- [ ] Unit testler yazıldı\n",
        "- [ ] Integration testler yapıldı\n",
        "- [ ] Load testing tamamlandı\n",
        "- [ ] Error scenarios test edildi\n",
        "\n",
        "#### ✅ Deployment\n",
        "- [ ] Dockerfile oluşturuldu\n",
        "- [ ] Docker Compose konfigürasyonu hazırlandı\n",
        "- [ ] Environment variables tanımlandı\n",
        "- [ ] Health checks konfigüre edildi\n",
        "\n",
        "#### ✅ Monitoring\n",
        "- [ ] Performance metrics toplanıyor\n",
        "- [ ] Error logging aktif\n",
        "- [ ] Health monitoring kuruldu\n",
        "- [ ] Alerting sistemi aktif\n",
        "\n",
        "### 💡 Advanced Deployment Strategies:\n",
        "\n",
        "1. **Blue-Green Deployment**: Zero-downtime deployment\n",
        "2. **Canary Deployment**: Gradual rollout\n",
        "3. **A/B Testing**: Model comparison in production\n",
        "4. **Auto-scaling**: Traffic'e göre scaling\n",
        "5. **Circuit Breaker**: Error durumunda koruma\n",
        "6. **Rate Limiting**: API abuse koruması\n",
        "\n",
        "### 🔧 Production Tools:\n",
        "\n",
        "- **Container Orchestration**: Kubernetes, Docker Swarm\n",
        "- **API Gateway**: Kong, Ambassador, AWS API Gateway\n",
        "- **Monitoring**: Prometheus, Grafana, ELK Stack\n",
        "- **CI/CD**: Jenkins, GitLab CI, GitHub Actions\n",
        "- **Cloud Platforms**: AWS, Azure, GCP\n",
        "- **Load Balancing**: Nginx, HAProxy, AWS ALB\n",
        "\n",
        "### 📈 Sonraki Adımlar:\n",
        "\n",
        "1. **Level 6 - Monitoring**: Model performance monitoring\n",
        "2. **A/B Testing**: Farklı model versiyonlarını test etme\n",
        "3. **Automated Retraining**: Data drift detection ve otomatik model güncelleme\n",
        "4. **Multi-model Serving**: Birden fazla modeli aynı API'de servis etme\n",
        "\n",
        "---\n",
        "\n",
        "**Level 5 Tamamlandı! 🎉**\n",
        "\n",
        "Artık ML modellerinizi production ortamında güvenle deploy edebilir, test edebilir ve monitor edebilirsiniz!\n",
        "\n",
        "### 📚 Ek Kaynaklar:\n",
        "\n",
        "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
        "- [Docker Best Practices](https://docs.docker.com/develop/best-practices/)\n",
        "- [MLOps Deployment Patterns](https://ml-ops.org/content/deployment-patterns)\n",
        "- [Model Serving Strategies](https://developers.google.com/machine-learning/guides/rules-of-ml)\n",
        "\n",
        "**🚀 Production'a hazır ML servisi oluşturdunuz!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
